{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classical_models.ipynb\n",
    "\n",
    "by: Archie Gertsman (arkadiy2@illinois.edu)\n",
    "Lloyd Fernandes (lloydf2@illinois.edu)\n",
    "\n",
    "Project director: Richard Sowers\n",
    "\n",
    "r-sowers@illinois.eduhttps://publish.illinois.edu/r-sowers/\n",
    "\n",
    "Copyright 2019 University of Illinois Board of Trustees. All Rights Reserved. Licensed under the MIT license\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../Lib/')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from feature_eng import split_trajectories\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from time import time\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>speed</th>\n",
       "      <th>lon_acc</th>\n",
       "      <th>lat_acc</th>\n",
       "      <th>type</th>\n",
       "      <th>traveled_d</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>bearing</th>\n",
       "      <th>nearest_edge_start_node</th>\n",
       "      <th>...</th>\n",
       "      <th>edge_progress_intervals</th>\n",
       "      <th>len</th>\n",
       "      <th>lanes</th>\n",
       "      <th>node_veh_dist</th>\n",
       "      <th>edge_seg</th>\n",
       "      <th>vehicle_density</th>\n",
       "      <th>avg_surr_speed</th>\n",
       "      <th>edge_bearing</th>\n",
       "      <th>acc_edge</th>\n",
       "      <th>acc_per_edge</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file_name</th>\n",
       "      <th>id</th>\n",
       "      <th>edge_id</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">4_1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">250699362_250699984</th>\n",
       "      <th>42.00</th>\n",
       "      <td>37.982746</td>\n",
       "      <td>23.732961</td>\n",
       "      <td>11.9046</td>\n",
       "      <td>-0.1145</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>Taxi</td>\n",
       "      <td>182.37</td>\n",
       "      <td>9.740748</td>\n",
       "      <td>1.570795</td>\n",
       "      <td>250699362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>97.581</td>\n",
       "      <td>5.4</td>\n",
       "      <td>29.814330</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>10.464171</td>\n",
       "      <td>-2.83013</td>\n",
       "      <td>0.113220</td>\n",
       "      <td>0.021953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42.04</th>\n",
       "      <td>37.982746</td>\n",
       "      <td>23.732963</td>\n",
       "      <td>11.8975</td>\n",
       "      <td>-0.1007</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>Taxi</td>\n",
       "      <td>182.37</td>\n",
       "      <td>9.740748</td>\n",
       "      <td>0.168572</td>\n",
       "      <td>250699362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>97.581</td>\n",
       "      <td>5.4</td>\n",
       "      <td>29.674830</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>10.457843</td>\n",
       "      <td>-2.83013</td>\n",
       "      <td>0.100360</td>\n",
       "      <td>0.016867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42.08</th>\n",
       "      <td>37.982747</td>\n",
       "      <td>23.732964</td>\n",
       "      <td>11.8919</td>\n",
       "      <td>-0.0918</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>Taxi</td>\n",
       "      <td>182.37</td>\n",
       "      <td>9.740748</td>\n",
       "      <td>0.168573</td>\n",
       "      <td>250699362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>97.581</td>\n",
       "      <td>5.4</td>\n",
       "      <td>29.537753</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>10.452857</td>\n",
       "      <td>-2.83013</td>\n",
       "      <td>0.092194</td>\n",
       "      <td>0.013188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42.12</th>\n",
       "      <td>37.982748</td>\n",
       "      <td>23.732965</td>\n",
       "      <td>11.8871</td>\n",
       "      <td>-0.0869</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>Taxi</td>\n",
       "      <td>182.37</td>\n",
       "      <td>9.740748</td>\n",
       "      <td>1.570796</td>\n",
       "      <td>250699362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>97.581</td>\n",
       "      <td>5.4</td>\n",
       "      <td>29.400718</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>10.448586</td>\n",
       "      <td>-2.83013</td>\n",
       "      <td>0.087837</td>\n",
       "      <td>0.010734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42.16</th>\n",
       "      <td>37.982748</td>\n",
       "      <td>23.732966</td>\n",
       "      <td>11.8831</td>\n",
       "      <td>-0.0784</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>Taxi</td>\n",
       "      <td>182.37</td>\n",
       "      <td>9.740748</td>\n",
       "      <td>0.328080</td>\n",
       "      <td>250699362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>97.581</td>\n",
       "      <td>5.4</td>\n",
       "      <td>29.330986</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>10.444986</td>\n",
       "      <td>-2.83013</td>\n",
       "      <td>0.080021</td>\n",
       "      <td>0.007273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              lat        lon    speed  \\\n",
       "file_name id edge_id             time                                   \n",
       "4_1       1  250699362_250699984 42.00  37.982746  23.732961  11.9046   \n",
       "                                 42.04  37.982746  23.732963  11.8975   \n",
       "                                 42.08  37.982747  23.732964  11.8919   \n",
       "                                 42.12  37.982748  23.732965  11.8871   \n",
       "                                 42.16  37.982748  23.732966  11.8831   \n",
       "\n",
       "                                        lon_acc  lat_acc  type  traveled_d  \\\n",
       "file_name id edge_id             time                                        \n",
       "4_1       1  250699362_250699984 42.00  -0.1145   0.0138  Taxi      182.37   \n",
       "                                 42.04  -0.1007   0.0147  Taxi      182.37   \n",
       "                                 42.08  -0.0918   0.0157  Taxi      182.37   \n",
       "                                 42.12  -0.0869   0.0167  Taxi      182.37   \n",
       "                                 42.16  -0.0784   0.0176  Taxi      182.37   \n",
       "\n",
       "                                        avg_speed   bearing  \\\n",
       "file_name id edge_id             time                         \n",
       "4_1       1  250699362_250699984 42.00   9.740748  1.570795   \n",
       "                                 42.04   9.740748  0.168572   \n",
       "                                 42.08   9.740748  0.168573   \n",
       "                                 42.12   9.740748  1.570796   \n",
       "                                 42.16   9.740748  0.328080   \n",
       "\n",
       "                                        nearest_edge_start_node  ...  \\\n",
       "file_name id edge_id             time                            ...   \n",
       "4_1       1  250699362_250699984 42.00                250699362  ...   \n",
       "                                 42.04                250699362  ...   \n",
       "                                 42.08                250699362  ...   \n",
       "                                 42.12                250699362  ...   \n",
       "                                 42.16                250699362  ...   \n",
       "\n",
       "                                        edge_progress_intervals     len  \\\n",
       "file_name id edge_id             time                                     \n",
       "4_1       1  250699362_250699984 42.00                      0.3  97.581   \n",
       "                                 42.04                      0.3  97.581   \n",
       "                                 42.08                      0.3  97.581   \n",
       "                                 42.12                      0.3  97.581   \n",
       "                                 42.16                      0.3  97.581   \n",
       "\n",
       "                                        lanes  node_veh_dist  edge_seg  \\\n",
       "file_name id edge_id             time                                    \n",
       "4_1       1  250699362_250699984 42.00    5.4      29.814330       1.0   \n",
       "                                 42.04    5.4      29.674830       1.0   \n",
       "                                 42.08    5.4      29.537753       1.0   \n",
       "                                 42.12    5.4      29.400718       1.0   \n",
       "                                 42.16    5.4      29.330986       1.0   \n",
       "\n",
       "                                        vehicle_density  avg_surr_speed  \\\n",
       "file_name id edge_id             time                                     \n",
       "4_1       1  250699362_250699984 42.00                7       10.464171   \n",
       "                                 42.04                7       10.457843   \n",
       "                                 42.08                7       10.452857   \n",
       "                                 42.12                7       10.448586   \n",
       "                                 42.16                7       10.444986   \n",
       "\n",
       "                                        edge_bearing  acc_edge  acc_per_edge  \n",
       "file_name id edge_id             time                                         \n",
       "4_1       1  250699362_250699984 42.00      -2.83013  0.113220      0.021953  \n",
       "                                 42.04      -2.83013  0.100360      0.016867  \n",
       "                                 42.08      -2.83013  0.092194      0.013188  \n",
       "                                 42.12      -2.83013  0.087837      0.010734  \n",
       "                                 42.16      -2.83013  0.080021      0.007273  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('block4_concat_lane.pkl')  \\\n",
    "    .set_index('edge_id', append=True) \\\n",
    "    .reorder_levels((0,1,3,2))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_agg(df, agg_dict, window_size=100, step=25):\n",
    "    # rolling agg with step size = 1\n",
    "    df_agg = df.groupby(df.index.names[:-1]) \\\n",
    "                .rolling(window_size) \\\n",
    "                .agg(agg_dict) \\\n",
    "                .dropna()\n",
    "    \n",
    "    # select a subset of above computations to achieve custom step size\n",
    "    df_agg = df_agg.groupby(df_agg.index.names, \n",
    "                            as_index=False, \n",
    "                            group_keys=False) \\\n",
    "                .apply(lambda x: x[::step])\n",
    "    \n",
    "    df_agg.columns = ['_'.join(col) for col in df_agg.columns]\n",
    "    \n",
    "    # add 'type' column\n",
    "    vehicle_types = df.type.groupby(df.index.names[:-1]).first()\n",
    "    return df_agg.join(vehicle_types)\n",
    "  \n",
    "def speed_ratio(grp, min_speed=0):\n",
    "    return len(grp[grp.speed > min_speed]) / len(grp)\n",
    "\n",
    "def validation_set(df,test_size):\n",
    "    \"\"\"dataframe is split based on their vehicle id's\"\"\"\n",
    "    df_val = df.reset_index()[[\"file_name\",'id','type']].drop_duplicates()\n",
    "    X,y = df_val[[\"file_name\",\"id\"]],df_val['type']\n",
    "    X_train,X_test,_,y_test = train_test_split(X, y, test_size=test_size, random_state=4, stratify=y) \n",
    "    df_train = df[df.index.droplevel(['time','edge_id']).isin(X_train.set_index(['file_name','id']).index)]\n",
    "    X_test['type'] = y_test\n",
    "    g = X_test.groupby('type')\n",
    "    X_test = g.apply(lambda group: group.sample(g.size().min())).reset_index(drop = True)\n",
    "    df_test = df[df.index.droplevel(['time','edge_id']).isin(X_test.set_index(['file_name','id']).index)]\n",
    "    return df_train,df_test\n",
    "\n",
    "def train_and_accuracy(X_train,y_train,X_test,y_test, model):\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_hat = model.predict(X_test)\n",
    "    a = y_hat==y_test\n",
    "    \n",
    "    f = f1_score((y_test == 'Car').astype(int),(y_hat == 'Car').astype(int))\n",
    "    return len(a[a==True]) / len(y_test),f\n",
    "\n",
    "def val_voting_accuracy(X_train,y_train,X_val,y_val, model,by_edge = False):\n",
    "\n",
    "    y_hat = model.predict(X_val)\n",
    "    if by_edge == False:\n",
    "        y_hat = pd.DataFrame(index = y_val.index,data = y_hat,columns = ['type'])\n",
    "\n",
    "        #predicted value for the entire trajectory would be the mode of the predicted labels\n",
    "        y_hat = y_hat.groupby(['file_name','id']).apply(lambda group: pd.Series.mode(group['type'])[0])\n",
    "        y_test = y_val.groupby(['file_name','id']).first(['type'])\n",
    "    else:\n",
    "        y_hat = pd.DataFrame(index = y_val.index,data = y_hat,columns = ['type'])\n",
    "\n",
    "        #predicted value for the entire trajectory would be the mode of the predicted labels\n",
    "        y_hat = y_hat.groupby(['file_name','id','edge_id']).apply(lambda group: pd.Series.mode(group['type'])[0])\n",
    "        y_test = y_val.groupby(['file_name','id','edge_id']).first(['type'])\n",
    "\n",
    "    a = y_hat==y_test\n",
    "   \n",
    "    f = f1_score((y_test == 'Car').astype(int),(y_hat == 'Car').astype(int))\n",
    "    return len(a[a==True]) / len(y_test),f\n",
    "\n",
    "def get_xy(df,overlap,traj_len,agg_dict,outlier_limit=None,balance = True):\n",
    "    \n",
    "    df_agg =rolling_agg(df, window_size=traj_len, step=int((1 - overlap)*traj_len),agg_dict = agg_dict)\n",
    "    if outlier_limit is not None:\n",
    "        df_agg = filter_by_percentile(df_agg,outlier_limit)\n",
    "    if balance == True:\n",
    "        g = df_agg.groupby('type', group_keys=False)\n",
    "        df_agg = g.apply(lambda grp: grp.sample(g.size().min()))\n",
    "        \n",
    "    X,y = df_agg.drop('type', axis=1), df_agg.type\n",
    "    return X,y\n",
    "  \n",
    "def filter_by_percentile(df,percentile):\n",
    "    \n",
    "    top_le = 1-(percentile/100)\n",
    "    bottom_le = percentile/100\n",
    "    df_top = df.quantile(top_le).reset_index()\n",
    "    df_top['cond'] ='('+df_top['index']+\" <= \"+df_top[top_le].astype(str)+')'\n",
    "    df_bottom = df.quantile(bottom_le).reset_index()\n",
    "    df_bottom['cond'] ='('+df_bottom['index']+\" >= \"+df_bottom[bottom_le].astype(str)+')'\n",
    "    df = df.query(df_top.cond.str.cat(sep=' & '))\n",
    "    df = df.query(df_bottom.cond.str.cat(sep=' & '))\n",
    "    \n",
    "    return df  \n",
    "\n",
    "def __xtrack_dist_diff(df):\n",
    "    \"\"\"splits a vehicle trajectory into smaller trajectories of fixed size and removes\n",
    "    the last (len(df) mod size) riws\n",
    "    \"\"\"\n",
    "    \n",
    "    df[\"xtrack_diff\"] = df.loc[:,['xtrack_dist']]- df.loc[:,['xtrack_dist']].shift(-1)\n",
    "    df[\"xtrack_diff\"]=df['xtrack_diff'].fillna(0)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.groupby(['file_name','id','edge_id'], as_index=False, group_keys=False) \\\n",
    "            .apply(__xtrack_dist_diff)\n",
    "df['xtrack_diff_sq'] = df['xtrack_diff']**2\n",
    "df['acc_edge_sq'] = df['acc_edge']**2\n",
    "df['acc_per_edge_sq'] = df['acc_per_edge']**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ensemble():\n",
    "    def __init__(self,model_num,accuracy_measure,model_list = None):\n",
    "        self.model_num = model_num\n",
    "        self.accuracy_measure = accuracy_measure\n",
    "        self.model_list = model_list\n",
    "        \n",
    "    def find_ensemble(self,df_acc,traj_len,vehicle_density):\n",
    "        self.model_list = df_acc.loc[(slice(None),'accuracy','mean'),(vehicle_density,traj_len,self.accuracy_measure)].sort_values(ascending = False).index.get_level_values(0)[:self.model_num].to_list()\n",
    "      \n",
    "    def fit(self,X,y,model_dict=None):\n",
    "        self.model_dict = model_dict\n",
    "        if model_dict == None:\n",
    "            self.model_dict = {}\n",
    "            for model in self.model_list:\n",
    "                self.model_dict[model] = model.fit(X,y)\n",
    "    \n",
    "    def predict(self,X):\n",
    "        label_list = []\n",
    "        df_model = pd.DataFrame(columns = self.model_list)\n",
    "        \n",
    "        for model in self.model_list:\n",
    "            df_model[model] = self.model_dict[model].predict(X)\n",
    "            \n",
    "        return df_model.apply(lambda x : x.mode(),axis = 1)[0].to_numpy()\n",
    "    \n",
    "    def predict_proba(self,X,get_label = True):\n",
    "        label_list = []\n",
    "        model = list(self.model_dict.values())[0]\n",
    "        df_model = pd.DataFrame(columns = pd.MultiIndex.from_product([self.model_list,model.classes_]))#,index = np.arange(0,len(X)))\n",
    "        #df_model.loc[:,('MLP',model.classes_)] =  model.predict_proba(X)\n",
    "        for name in self.model_list:\n",
    "            model = self.model_dict[name]\n",
    "            df_model[:,(name,model.classes_)] = model.predict_proba(X)\n",
    "            \n",
    "        df_model = df_model.mean(axis=1, level=[1])\n",
    "        if get_label == True:\n",
    "            return df_model.idxmax(axis=1)\n",
    "        else:\n",
    "            return df_model\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial parameters\n",
    "models = {\n",
    "        'Random Forest': Pipeline([('scaler', StandardScaler()), ('rf', RandomForestClassifier())]),\n",
    "        'AdaBoost':Pipeline([('scaler', StandardScaler()), ('abc', AdaBoostClassifier())]) ,\n",
    "        'SVM': Pipeline([('scaler', StandardScaler()), ('svc', SVC(max_iter=10000))]) ,\n",
    "        'Log Regression': Pipeline([('scaler', StandardScaler()), ('lr', LogisticRegression(max_iter=10000))]) ,\n",
    "        'GBM': Pipeline([('scaler', StandardScaler()), ('gbm', GradientBoostingClassifier())]),\n",
    "        'MLP': Pipeline([('scaler', StandardScaler()), ('mlp', MLPClassifier(hidden_layer_sizes = (250,100,25),max_iter=1000,\\\n",
    "                                                                             learning_rate = 'adaptive',early_stopping = True,n_iter_no_change = 10))])\n",
    "                        \n",
    "    }\n",
    "\n",
    "df_acc = pd.DataFrame(index=pd.MultiIndex.from_product([models.keys(),['f1_score','accuracy'], ['mean']]))\n",
    "overlap = 0.4\n",
    "min_movement_limit = 0.75\n",
    "speed_limit = 0\n",
    "k = 5\n",
    "validation_ratio = 0.2\n",
    "kf = StratifiedKFold(n_splits=k, shuffle=True)\n",
    "accs = np.zeros(k)\n",
    "f1 = np.zeros(k)\n",
    " \n",
    "agg_dict = {'xtrack_diff': ['mean','std'],\n",
    "            'xtrack_dist': ['mean','std'],\n",
    "            'avg_surr_speed': ['skew',pd.DataFrame.kurt],\n",
    "            #'lanes':['mean'],\n",
    "            'speed':['mean'],#,'skew',pd.DataFrame.kurt],\n",
    "            'vehicle_density': ['mean'],#,'std','skew',pd.DataFrame.kurt],\n",
    "            'acc_edge': ['mean','skew'],\n",
    "            'acc_per_edge': ['mean','std']}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of trajectories:  6430\n",
      "No of trajectories:  3642\n",
      "No of trajectories:  2322\n",
      "No of trajectories:  1682\n",
      "vehicle density >=   1\n",
      "No of trajectories:  3694\n",
      "No of trajectories:  2242\n",
      "No of trajectories:  1358\n",
      "No of trajectories:  916\n",
      "vehicle density >=   2\n",
      "No of trajectories:  1810\n",
      "No of trajectories:  984\n",
      "No of trajectories:  634\n",
      "No of trajectories:  444\n",
      "vehicle density >=   3\n",
      "No of trajectories:  798\n",
      "No of trajectories:  432\n",
      "No of trajectories:  250\n",
      "No of trajectories:  184\n",
      "vehicle density >=   4\n",
      "No of trajectories:  324\n",
      "No of trajectories:  206\n",
      "No of trajectories:  110\n",
      "No of trajectories:  66\n",
      "vehicle density >=   5\n"
     ]
    }
   ],
   "source": [
    "# Car and Taxi classification\n",
    "\n",
    "traj_lens = np.arange(100,300, step=50)\n",
    "model_num = 5\n",
    "df_acc = pd.DataFrame(columns = pd.MultiIndex.from_product([list(range(0,6)),traj_lens,['kfold','val_woedge','val_by_edge']]),index=pd.MultiIndex.from_product([models.keys(),['accuracy','accuracy_baseline'], ['mean','std']]))\n",
    "ensemble_model = ensemble(model_num,'kfold')\n",
    "\n",
    "validation_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "\n",
    "for vehicle_density in range(1,6):\n",
    "    df_vehicle_density = df[df.vehicle_density >= vehicle_density]\n",
    "    for traj_len in traj_lens:\n",
    "\n",
    "        df_filtered = df_vehicle_density.groupby(df_vehicle_density.index.names[:-1]) \\\n",
    "                .filter(lambda grp: (len(grp) >= traj_len) & (speed_ratio(grp,speed_limit) >= min_movement_limit))\n",
    "\n",
    "        df_train_test,df_val = validation_set(df_filtered,validation_ratio)\n",
    "        df_train,df_test = validation_set(df_train_test,test_ratio)\n",
    "        #aggregate trajectories\n",
    "        X,y = get_xy(df_train_test,overlap,traj_len,agg_dict,1)\n",
    "        X_train,y_train = get_xy(df_train,overlap,traj_len,agg_dict,1)\n",
    "        X_test,y_test = get_xy(df_test,overlap,traj_len,agg_dict,balance = False)\n",
    "        X_val,y_val = get_xy(df_val,overlap,traj_len,agg_dict,balance = False)\n",
    "        \n",
    "        #store percent cars and taxis\n",
    "        print(\"No of trajectories: \",len(X))\n",
    "        df_acc.loc[('traj_len','Car_Taxi','total'), (vehicle_density,traj_len,'kfold')] = len(X)\n",
    "        df_acc.loc[('traj_len','Car_Taxi_percent','Car'), (vehicle_density,traj_len,'kfold')] = sum(y == 'Car')/len(X)\n",
    "        df_acc.loc[('traj_len','Car_Taxi_percent','Taxi'), (vehicle_density,traj_len,'kfold')] = sum(y == 'Taxi')/ len(X)\n",
    "\n",
    "        woedge_count = y_val.reset_index(['edge_id'],drop = True).reset_index().drop_duplicates()\n",
    "        df_acc.loc[('traj_len','Car_Taxi','total'), (vehicle_density,traj_len,'val_woedge')] = len(woedge_count)\n",
    "        df_acc.loc[('traj_len','Car_Taxi_percent','Car'), (vehicle_density,traj_len,'val_woedge')] = sum(woedge_count.type == 'Car')/len(woedge_count)\n",
    "        df_acc.loc[('traj_len','Car_Taxi_percent','Taxi'), (vehicle_density,traj_len,'val_woedge')] =sum(woedge_count.type == 'Taxi')/len(woedge_count)\n",
    "\n",
    "        by_edge_count = y_val.reset_index().drop_duplicates()\n",
    "        df_acc.loc[('traj_len','Car_Taxi','total'), (vehicle_density,traj_len,'val_by_edge')] = len(by_edge_count)\n",
    "        df_acc.loc[('traj_len','Car_Taxi_percent','Car'), (vehicle_density,traj_len,'val_by_edge')] = sum(by_edge_count.type == 'Car')/len(by_edge_count)\n",
    "        df_acc.loc[('traj_len','Car_Taxi_percent','Taxi'), (vehicle_density,traj_len,'val_by_edge')] = sum(by_edge_count.type == 'Taxi')/len(by_edge_count)\n",
    "\n",
    "        model_dict = {}\n",
    "        # fit different models\n",
    "        for name, model in models.items():\n",
    "            \n",
    "#             for i, (train_index, test_index) in enumerate(kf.split(X,y)):\n",
    "\n",
    "#                 X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "#                 y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "#                 accs[i],f1[i] = train_and_accuracy(X_train, y_train,X_test,y_test, model)\n",
    "            model.fit(X_train,y_train)\n",
    "            val_accs,val_f1 = val_voting_accuracy(X_train, y_train,X_test,y_test, model)\n",
    "            \n",
    "            df_acc.loc[(name, 'accuracy','mean'),  (vehicle_density,traj_len,'kfold')] = round(100*val_accs, 3)\n",
    "\n",
    "            model.fit(X, y)\n",
    "            val_accs,val_f1 = val_voting_accuracy(X, y,X_val,y_val, model)\n",
    "            df_acc.loc[(name, 'accuracy','mean'), (vehicle_density,traj_len,'val_woedge')] = round(100*val_accs, 3)\n",
    "            #df_acc.loc[(name, 'f1_score','mean'),(str(traj_len)+'_val_woedge')] = round(100*val_f1, 3)\n",
    "\n",
    "            val_accs,val_f1 = val_voting_accuracy(X, y,X_val,y_val, model,by_edge = True)\n",
    "            df_acc.loc[(name, 'accuracy','mean'), (vehicle_density,traj_len,'val_by_edge')] = round(100*val_accs, 3)\n",
    "            #df_acc.loc[(name, 'f1_score','mean'),(str(traj_len)+'_val_by_edge')] = round(100*val_f1, 3)\n",
    "            model_dict[name] = model\n",
    "            \n",
    "        ensemble_model.find_ensemble(df_acc,traj_len,vehicle_density)\n",
    "        ensemble_model.fit(X,y,model_dict)\n",
    "        val_accs,val_f1 = val_voting_accuracy(X, y,X_val,y_val, ensemble_model)\n",
    "        df_acc.loc[('ensemble_model', 'accuracy','mean'), (vehicle_density,traj_len,'val_woedge')] = round(100*val_accs, 3)\n",
    "        val_accs,val_f1 = val_voting_accuracy(X, y,X_val,y_val, ensemble_model,by_edge = True)\n",
    "        df_acc.loc[('ensemble_model', 'accuracy','mean'), (vehicle_density,traj_len,'val_by_edge')] = round(100*val_accs, 3)\n",
    "            \n",
    "    print('vehicle density >=  ',vehicle_density)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of trajectories:  6076\n",
      "No of trajectories:  6076\n",
      "No of trajectories:  3466\n",
      "No of trajectories:  3466\n",
      "No of trajectories:  2096\n",
      "No of trajectories:  2096\n",
      "No of trajectories:  1510\n",
      "No of trajectories:  1510\n",
      "vehicle density >=   1\n",
      "No of trajectories:  3146\n",
      "No of trajectories:  3146\n",
      "No of trajectories:  1896\n",
      "No of trajectories:  1896\n",
      "No of trajectories:  1192\n",
      "No of trajectories:  1192\n",
      "No of trajectories:  784\n",
      "No of trajectories:  784\n",
      "vehicle density >=   2\n",
      "No of trajectories:  1666\n",
      "No of trajectories:  1666\n",
      "No of trajectories:  870\n",
      "No of trajectories:  870\n",
      "No of trajectories:  518\n",
      "No of trajectories:  518\n",
      "No of trajectories:  394\n",
      "No of trajectories:  394\n",
      "vehicle density >=   3\n",
      "No of trajectories:  732\n",
      "No of trajectories:  732\n",
      "No of trajectories:  402\n",
      "No of trajectories:  402\n",
      "No of trajectories:  232\n",
      "No of trajectories:  232\n",
      "No of trajectories:  158\n",
      "No of trajectories:  158\n",
      "vehicle density >=   4\n",
      "No of trajectories:  274\n",
      "No of trajectories:  274\n",
      "No of trajectories:  148\n",
      "No of trajectories:  148\n",
      "No of trajectories:  74\n",
      "No of trajectories:  74\n",
      "No of trajectories:  52\n",
      "No of trajectories:  52\n",
      "vehicle density >=   5\n"
     ]
    }
   ],
   "source": [
    "# Car and Car_1 classification\n",
    "\n",
    "df_car = df[df.type == 'Car']\n",
    "ensemble_model = ensemble(model_num,'kfold')\n",
    "for vehicle_density in range(1,6):\n",
    "    df_vehicle_density = df_car[df_car.vehicle_density >= vehicle_density]\n",
    "    for traj_len in traj_lens:\n",
    "\n",
    "        df_filtered = df_vehicle_density.groupby(df_vehicle_density.index.names[:-1]) \\\n",
    "                .filter(lambda grp: (len(grp) >= traj_len) & (speed_ratio(grp,speed_limit) >= min_movement_limit))\n",
    "        \n",
    "        df_index = df_filtered.reset_index()[['file_name','id']].drop_duplicates()\n",
    "        df_filtered.loc[df_filtered.reset_index(['edge_id', 'time'],drop = True).index.isin(df_index.sample(frac = 0.5).set_index(['file_name','id']).index),'type']='Car_1'\n",
    "        \n",
    "        df_train_test,df_val = validation_set(df_filtered,validation_ratio)\n",
    "        df_train,df_test = validation_set(df_train_test,test_ratio)\n",
    "        #aggregate trajectories\n",
    "        X,y = get_xy(df_train_test,overlap,traj_len,agg_dict,1)\n",
    "        X_train,y_train = get_xy(df_train,overlap,traj_len,agg_dict,1)\n",
    "        X_test,y_test = get_xy(df_test,overlap,traj_len,agg_dict,balance = False)\n",
    "        X_val,y_val = get_xy(df_val,overlap,traj_len,agg_dict,balance = False)\n",
    "        \n",
    "        #store percent cars and taxis\n",
    "        print(\"No of trajectories: \",len(X))\n",
    "        print(\"No of trajectories: \",len(X))\n",
    "        df_acc.loc[('traj_len','Car_Car','total'), (vehicle_density,traj_len,'kfold')] = len(X)\n",
    "        df_acc.loc[('traj_len','Car_Car_percent','Car'), (vehicle_density,traj_len,'kfold')] = sum(y == 'Car')/len(X)\n",
    "        df_acc.loc[('traj_len','Car_Car_percent','Car_1'), (vehicle_density,traj_len,'kfold')] = sum(y == 'Car_1')/ len(X)\n",
    "\n",
    "        woedge_count = y_val.reset_index(['edge_id'],drop = True).reset_index().drop_duplicates()\n",
    "        df_acc.loc[('traj_len','Car_Car','total'), (vehicle_density,traj_len,'val_woedge')] = len(woedge_count)\n",
    "        df_acc.loc[('traj_len','Car_Car_percent','Car'), (vehicle_density,traj_len,'val_woedge')] = sum(woedge_count.type == 'Car')/len(woedge_count)\n",
    "        df_acc.loc[('traj_len','Car_Car_percent','Car_1'), (vehicle_density,traj_len,'val_woedge')] =sum(woedge_count.type == 'Car_1')/len(woedge_count)\n",
    "\n",
    "        by_edge_count = y_val.reset_index().drop_duplicates()\n",
    "        df_acc.loc[('traj_len','Car_Car','total'), (vehicle_density,traj_len,'val_by_edge')] = len(by_edge_count)\n",
    "        df_acc.loc[('traj_len','Car_Car_percent','Car'), (vehicle_density,traj_len,'val_by_edge')] = sum(by_edge_count.type == 'Car')/len(by_edge_count)\n",
    "        df_acc.loc[('traj_len','Car_Car_percent','Car_1'), (vehicle_density,traj_len,'val_by_edge')] = sum(by_edge_count.type == 'Car_1')/len(by_edge_count)\n",
    "        model_dict = {}\n",
    "        # fit different models\n",
    "        for name, model in models.items():\n",
    "           \n",
    "\n",
    "            model.fit(X_train,y_train)\n",
    "            val_accs,val_f1 = val_voting_accuracy(X_train, y_train,X_test,y_test, model)\n",
    "            \n",
    "            df_acc.loc[(name, 'accuracy_baseline','mean'),  (vehicle_density,traj_len,'kfold')] = round(100*val_accs, 3)\n",
    "\n",
    "            model.fit(X, y)\n",
    "            val_accs,val_f1 = val_voting_accuracy(X, y,X_val,y_val, model)\n",
    "            df_acc.loc[(name, 'accuracy_baseline','mean'), (vehicle_density,traj_len,'val_woedge')] = round(100*val_accs, 3)\n",
    "           \n",
    "            val_accs,val_f1 = val_voting_accuracy(X, y,X_val,y_val, model,by_edge = True)\n",
    "            df_acc.loc[(name, 'accuracy_baseline','mean'), (vehicle_density,traj_len,'val_by_edge')] = round(100*val_accs, 3)\n",
    "            model_dict[name] = model\n",
    "\n",
    "            \n",
    "       \n",
    "        ensemble_model.find_ensemble(df_acc,traj_len,vehicle_density)\n",
    "        ensemble_model.fit(X,y,model_dict)\n",
    "        val_accs,val_f1 = val_voting_accuracy(X, y,X_val,y_val, ensemble_model)\n",
    "        df_acc.loc[('ensemble_model', 'accuracy_baseline','mean'), (vehicle_density,traj_len,'val_woedge')] = round(100*val_accs, 3)\n",
    "        val_accs,val_f1 = val_voting_accuracy(X, y,X_val,y_val, ensemble_model,by_edge = True)\n",
    "        df_acc.loc[('ensemble_model', 'accuracy_baseline','mean'), (vehicle_density,traj_len,'val_by_edge')] = round(100*val_accs, 3)\n",
    "        \n",
    "            \n",
    "    print('vehicle density >=  ',vehicle_density)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">1</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">100</th>\n",
       "      <th colspan=\"3\" halign=\"left\">150</th>\n",
       "      <th colspan=\"3\" halign=\"left\">200</th>\n",
       "      <th>250</th>\n",
       "      <th>...</th>\n",
       "      <th>100</th>\n",
       "      <th colspan=\"3\" halign=\"left\">150</th>\n",
       "      <th colspan=\"3\" halign=\"left\">200</th>\n",
       "      <th colspan=\"3\" halign=\"left\">250</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>kfold</th>\n",
       "      <th>val_woedge</th>\n",
       "      <th>val_by_edge</th>\n",
       "      <th>kfold</th>\n",
       "      <th>val_woedge</th>\n",
       "      <th>val_by_edge</th>\n",
       "      <th>kfold</th>\n",
       "      <th>val_woedge</th>\n",
       "      <th>val_by_edge</th>\n",
       "      <th>kfold</th>\n",
       "      <th>...</th>\n",
       "      <th>val_by_edge</th>\n",
       "      <th>kfold</th>\n",
       "      <th>val_woedge</th>\n",
       "      <th>val_by_edge</th>\n",
       "      <th>kfold</th>\n",
       "      <th>val_woedge</th>\n",
       "      <th>val_by_edge</th>\n",
       "      <th>kfold</th>\n",
       "      <th>val_woedge</th>\n",
       "      <th>val_by_edge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Random Forest</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>mean</th>\n",
       "      <td>63.0</td>\n",
       "      <td>59.274</td>\n",
       "      <td>55.802</td>\n",
       "      <td>56.522</td>\n",
       "      <td>56.087</td>\n",
       "      <td>53.672</td>\n",
       "      <td>54.268</td>\n",
       "      <td>51.471</td>\n",
       "      <td>50.523</td>\n",
       "      <td>57.746</td>\n",
       "      <td>...</td>\n",
       "      <td>46.667</td>\n",
       "      <td>68.75</td>\n",
       "      <td>63.636</td>\n",
       "      <td>63.636</td>\n",
       "      <td>41.667</td>\n",
       "      <td>57.143</td>\n",
       "      <td>62.5</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>61.538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_baseline</th>\n",
       "      <th>mean</th>\n",
       "      <td>49.55</td>\n",
       "      <td>51.439</td>\n",
       "      <td>49.375</td>\n",
       "      <td>51.0</td>\n",
       "      <td>47.6</td>\n",
       "      <td>46.31</td>\n",
       "      <td>51.724</td>\n",
       "      <td>50.459</td>\n",
       "      <td>50.47</td>\n",
       "      <td>48.611</td>\n",
       "      <td>...</td>\n",
       "      <td>63.636</td>\n",
       "      <td>27.778</td>\n",
       "      <td>72.727</td>\n",
       "      <td>73.913</td>\n",
       "      <td>41.667</td>\n",
       "      <td>64.286</td>\n",
       "      <td>64.286</td>\n",
       "      <td>50.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">AdaBoost</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>mean</th>\n",
       "      <td>59.5</td>\n",
       "      <td>57.258</td>\n",
       "      <td>56.049</td>\n",
       "      <td>54.348</td>\n",
       "      <td>55.217</td>\n",
       "      <td>53.672</td>\n",
       "      <td>56.098</td>\n",
       "      <td>51.961</td>\n",
       "      <td>51.22</td>\n",
       "      <td>59.859</td>\n",
       "      <td>...</td>\n",
       "      <td>46.667</td>\n",
       "      <td>62.5</td>\n",
       "      <td>59.091</td>\n",
       "      <td>59.091</td>\n",
       "      <td>50.0</td>\n",
       "      <td>71.429</td>\n",
       "      <td>75.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>61.538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_baseline</th>\n",
       "      <th>mean</th>\n",
       "      <td>50.0</td>\n",
       "      <td>52.158</td>\n",
       "      <td>52.708</td>\n",
       "      <td>54.5</td>\n",
       "      <td>50.8</td>\n",
       "      <td>49.618</td>\n",
       "      <td>54.023</td>\n",
       "      <td>50.459</td>\n",
       "      <td>49.843</td>\n",
       "      <td>50.694</td>\n",
       "      <td>...</td>\n",
       "      <td>48.485</td>\n",
       "      <td>44.444</td>\n",
       "      <td>63.636</td>\n",
       "      <td>60.87</td>\n",
       "      <td>33.333</td>\n",
       "      <td>57.143</td>\n",
       "      <td>57.143</td>\n",
       "      <td>62.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>mean</th>\n",
       "      <td>60.0</td>\n",
       "      <td>58.871</td>\n",
       "      <td>57.531</td>\n",
       "      <td>58.152</td>\n",
       "      <td>58.696</td>\n",
       "      <td>54.802</td>\n",
       "      <td>54.878</td>\n",
       "      <td>52.451</td>\n",
       "      <td>52.613</td>\n",
       "      <td>61.972</td>\n",
       "      <td>...</td>\n",
       "      <td>46.667</td>\n",
       "      <td>62.5</td>\n",
       "      <td>59.091</td>\n",
       "      <td>59.091</td>\n",
       "      <td>41.667</td>\n",
       "      <td>71.429</td>\n",
       "      <td>75.0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>53.846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_baseline</th>\n",
       "      <th>mean</th>\n",
       "      <td>50.0</td>\n",
       "      <td>52.878</td>\n",
       "      <td>50.625</td>\n",
       "      <td>49.0</td>\n",
       "      <td>48.8</td>\n",
       "      <td>49.873</td>\n",
       "      <td>52.874</td>\n",
       "      <td>53.211</td>\n",
       "      <td>52.978</td>\n",
       "      <td>55.556</td>\n",
       "      <td>...</td>\n",
       "      <td>39.394</td>\n",
       "      <td>33.333</td>\n",
       "      <td>68.182</td>\n",
       "      <td>69.565</td>\n",
       "      <td>33.333</td>\n",
       "      <td>35.714</td>\n",
       "      <td>35.714</td>\n",
       "      <td>62.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Log Regression</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>mean</th>\n",
       "      <td>55.0</td>\n",
       "      <td>51.613</td>\n",
       "      <td>51.358</td>\n",
       "      <td>53.261</td>\n",
       "      <td>56.087</td>\n",
       "      <td>52.542</td>\n",
       "      <td>52.439</td>\n",
       "      <td>54.902</td>\n",
       "      <td>52.962</td>\n",
       "      <td>56.338</td>\n",
       "      <td>...</td>\n",
       "      <td>43.333</td>\n",
       "      <td>75.0</td>\n",
       "      <td>54.545</td>\n",
       "      <td>54.545</td>\n",
       "      <td>25.0</td>\n",
       "      <td>71.429</td>\n",
       "      <td>75.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>69.231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_baseline</th>\n",
       "      <th>mean</th>\n",
       "      <td>45.045</td>\n",
       "      <td>53.597</td>\n",
       "      <td>53.125</td>\n",
       "      <td>52.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>49.364</td>\n",
       "      <td>51.724</td>\n",
       "      <td>51.376</td>\n",
       "      <td>50.157</td>\n",
       "      <td>53.472</td>\n",
       "      <td>...</td>\n",
       "      <td>45.455</td>\n",
       "      <td>27.778</td>\n",
       "      <td>63.636</td>\n",
       "      <td>60.87</td>\n",
       "      <td>25.0</td>\n",
       "      <td>21.429</td>\n",
       "      <td>21.429</td>\n",
       "      <td>50.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">GBM</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>mean</th>\n",
       "      <td>60.0</td>\n",
       "      <td>55.645</td>\n",
       "      <td>53.333</td>\n",
       "      <td>60.326</td>\n",
       "      <td>54.783</td>\n",
       "      <td>53.39</td>\n",
       "      <td>53.049</td>\n",
       "      <td>51.961</td>\n",
       "      <td>50.871</td>\n",
       "      <td>59.155</td>\n",
       "      <td>...</td>\n",
       "      <td>53.333</td>\n",
       "      <td>68.75</td>\n",
       "      <td>63.636</td>\n",
       "      <td>63.636</td>\n",
       "      <td>25.0</td>\n",
       "      <td>78.571</td>\n",
       "      <td>75.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>92.308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_baseline</th>\n",
       "      <th>mean</th>\n",
       "      <td>46.847</td>\n",
       "      <td>49.281</td>\n",
       "      <td>47.917</td>\n",
       "      <td>52.0</td>\n",
       "      <td>45.6</td>\n",
       "      <td>47.583</td>\n",
       "      <td>47.126</td>\n",
       "      <td>55.505</td>\n",
       "      <td>53.918</td>\n",
       "      <td>49.306</td>\n",
       "      <td>...</td>\n",
       "      <td>54.545</td>\n",
       "      <td>27.778</td>\n",
       "      <td>72.727</td>\n",
       "      <td>73.913</td>\n",
       "      <td>41.667</td>\n",
       "      <td>64.286</td>\n",
       "      <td>64.286</td>\n",
       "      <td>25.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>mean</th>\n",
       "      <td>57.0</td>\n",
       "      <td>58.468</td>\n",
       "      <td>57.037</td>\n",
       "      <td>53.261</td>\n",
       "      <td>59.13</td>\n",
       "      <td>55.932</td>\n",
       "      <td>55.488</td>\n",
       "      <td>55.392</td>\n",
       "      <td>55.749</td>\n",
       "      <td>63.38</td>\n",
       "      <td>...</td>\n",
       "      <td>43.333</td>\n",
       "      <td>68.75</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>66.667</td>\n",
       "      <td>71.429</td>\n",
       "      <td>68.75</td>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>53.846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_baseline</th>\n",
       "      <th>mean</th>\n",
       "      <td>47.748</td>\n",
       "      <td>50.36</td>\n",
       "      <td>48.75</td>\n",
       "      <td>50.0</td>\n",
       "      <td>45.6</td>\n",
       "      <td>48.601</td>\n",
       "      <td>53.448</td>\n",
       "      <td>51.376</td>\n",
       "      <td>50.784</td>\n",
       "      <td>52.778</td>\n",
       "      <td>...</td>\n",
       "      <td>48.485</td>\n",
       "      <td>50.0</td>\n",
       "      <td>40.909</td>\n",
       "      <td>39.13</td>\n",
       "      <td>50.0</td>\n",
       "      <td>42.857</td>\n",
       "      <td>42.857</td>\n",
       "      <td>75.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ensemble_model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58.871</td>\n",
       "      <td>55.309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.826</td>\n",
       "      <td>54.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.451</td>\n",
       "      <td>52.962</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>46.667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.182</td>\n",
       "      <td>68.182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.143</td>\n",
       "      <td>62.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "      <td>69.231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_baseline</th>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>51.799</td>\n",
       "      <td>49.792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>47.583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.211</td>\n",
       "      <td>52.978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>57.576</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.182</td>\n",
       "      <td>65.217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.857</td>\n",
       "      <td>42.857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">traj_len</th>\n",
       "      <th>Car_Taxi_percent</th>\n",
       "      <th>Car</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.491358</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.471751</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.491289</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Car_Car_percent</th>\n",
       "      <th>Car</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.496183</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.473354</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Car_1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.503817</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.526646</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Car_Taxi_percent</th>\n",
       "      <th>Taxi</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.508642</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.528249</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.508711</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Car_Taxi</th>\n",
       "      <th>total</th>\n",
       "      <td>6430</td>\n",
       "      <td>248</td>\n",
       "      <td>405</td>\n",
       "      <td>3642</td>\n",
       "      <td>230</td>\n",
       "      <td>354</td>\n",
       "      <td>2322</td>\n",
       "      <td>204</td>\n",
       "      <td>287</td>\n",
       "      <td>1682</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>206</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>110</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>66</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Car_Car</th>\n",
       "      <th>total</th>\n",
       "      <td>6076</td>\n",
       "      <td>278</td>\n",
       "      <td>480</td>\n",
       "      <td>3466</td>\n",
       "      <td>250</td>\n",
       "      <td>393</td>\n",
       "      <td>2096</td>\n",
       "      <td>218</td>\n",
       "      <td>319</td>\n",
       "      <td>1510</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>148</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>74</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>52</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             1                                 \\\n",
       "                                           100                            150   \n",
       "                                         kfold val_woedge val_by_edge   kfold   \n",
       "Random Forest  accuracy          mean     63.0     59.274      55.802  56.522   \n",
       "               accuracy_baseline mean    49.55     51.439      49.375    51.0   \n",
       "AdaBoost       accuracy          mean     59.5     57.258      56.049  54.348   \n",
       "               accuracy_baseline mean     50.0     52.158      52.708    54.5   \n",
       "SVM            accuracy          mean     60.0     58.871      57.531  58.152   \n",
       "               accuracy_baseline mean     50.0     52.878      50.625    49.0   \n",
       "Log Regression accuracy          mean     55.0     51.613      51.358  53.261   \n",
       "               accuracy_baseline mean   45.045     53.597      53.125    52.0   \n",
       "GBM            accuracy          mean     60.0     55.645      53.333  60.326   \n",
       "               accuracy_baseline mean   46.847     49.281      47.917    52.0   \n",
       "MLP            accuracy          mean     57.0     58.468      57.037  53.261   \n",
       "               accuracy_baseline mean   47.748      50.36       48.75    50.0   \n",
       "ensemble_model accuracy          mean      NaN     58.871      55.309     NaN   \n",
       "               accuracy_baseline mean      NaN     51.799      49.792     NaN   \n",
       "traj_len       Car_Taxi_percent  Car       0.5        0.5    0.491358     0.5   \n",
       "               Car_Car_percent   Car       0.5        0.5         0.5     0.5   \n",
       "                                 Car_1     0.5        0.5         0.5     0.5   \n",
       "               Car_Taxi_percent  Taxi      0.5        0.5    0.508642     0.5   \n",
       "               Car_Taxi          total    6430        248         405    3642   \n",
       "               Car_Car           total    6076        278         480    3466   \n",
       "\n",
       "                                                                       \\\n",
       "                                                                  200   \n",
       "                                       val_woedge val_by_edge   kfold   \n",
       "Random Forest  accuracy          mean      56.087      53.672  54.268   \n",
       "               accuracy_baseline mean        47.6       46.31  51.724   \n",
       "AdaBoost       accuracy          mean      55.217      53.672  56.098   \n",
       "               accuracy_baseline mean        50.8      49.618  54.023   \n",
       "SVM            accuracy          mean      58.696      54.802  54.878   \n",
       "               accuracy_baseline mean        48.8      49.873  52.874   \n",
       "Log Regression accuracy          mean      56.087      52.542  52.439   \n",
       "               accuracy_baseline mean        50.0      49.364  51.724   \n",
       "GBM            accuracy          mean      54.783       53.39  53.049   \n",
       "               accuracy_baseline mean        45.6      47.583  47.126   \n",
       "MLP            accuracy          mean       59.13      55.932  55.488   \n",
       "               accuracy_baseline mean        45.6      48.601  53.448   \n",
       "ensemble_model accuracy          mean      57.826       54.52     NaN   \n",
       "               accuracy_baseline mean        46.0      47.583     NaN   \n",
       "traj_len       Car_Taxi_percent  Car          0.5    0.471751     0.5   \n",
       "               Car_Car_percent   Car          0.5    0.496183     0.5   \n",
       "                                 Car_1        0.5    0.503817     0.5   \n",
       "               Car_Taxi_percent  Taxi         0.5    0.528249     0.5   \n",
       "               Car_Taxi          total        230         354    2322   \n",
       "               Car_Car           total        250         393    2096   \n",
       "\n",
       "                                                                       ...  \\\n",
       "                                                                  250  ...   \n",
       "                                       val_woedge val_by_edge   kfold  ...   \n",
       "Random Forest  accuracy          mean      51.471      50.523  57.746  ...   \n",
       "               accuracy_baseline mean      50.459       50.47  48.611  ...   \n",
       "AdaBoost       accuracy          mean      51.961       51.22  59.859  ...   \n",
       "               accuracy_baseline mean      50.459      49.843  50.694  ...   \n",
       "SVM            accuracy          mean      52.451      52.613  61.972  ...   \n",
       "               accuracy_baseline mean      53.211      52.978  55.556  ...   \n",
       "Log Regression accuracy          mean      54.902      52.962  56.338  ...   \n",
       "               accuracy_baseline mean      51.376      50.157  53.472  ...   \n",
       "GBM            accuracy          mean      51.961      50.871  59.155  ...   \n",
       "               accuracy_baseline mean      55.505      53.918  49.306  ...   \n",
       "MLP            accuracy          mean      55.392      55.749   63.38  ...   \n",
       "               accuracy_baseline mean      51.376      50.784  52.778  ...   \n",
       "ensemble_model accuracy          mean      52.451      52.962     NaN  ...   \n",
       "               accuracy_baseline mean      53.211      52.978     NaN  ...   \n",
       "traj_len       Car_Taxi_percent  Car          0.5    0.491289     0.5  ...   \n",
       "               Car_Car_percent   Car          0.5    0.473354     0.5  ...   \n",
       "                                 Car_1        0.5    0.526646     0.5  ...   \n",
       "               Car_Taxi_percent  Taxi         0.5    0.508711     0.5  ...   \n",
       "               Car_Taxi          total        204         287    1682  ...   \n",
       "               Car_Car           total        218         319    1510  ...   \n",
       "\n",
       "                                                 5                     \\\n",
       "                                               100     150              \n",
       "                                       val_by_edge   kfold val_woedge   \n",
       "Random Forest  accuracy          mean       46.667   68.75     63.636   \n",
       "               accuracy_baseline mean       63.636  27.778     72.727   \n",
       "AdaBoost       accuracy          mean       46.667    62.5     59.091   \n",
       "               accuracy_baseline mean       48.485  44.444     63.636   \n",
       "SVM            accuracy          mean       46.667    62.5     59.091   \n",
       "               accuracy_baseline mean       39.394  33.333     68.182   \n",
       "Log Regression accuracy          mean       43.333    75.0     54.545   \n",
       "               accuracy_baseline mean       45.455  27.778     63.636   \n",
       "GBM            accuracy          mean       53.333   68.75     63.636   \n",
       "               accuracy_baseline mean       54.545  27.778     72.727   \n",
       "MLP            accuracy          mean       43.333   68.75       50.0   \n",
       "               accuracy_baseline mean       48.485    50.0     40.909   \n",
       "ensemble_model accuracy          mean       46.667     NaN     68.182   \n",
       "               accuracy_baseline mean       57.576     NaN     68.182   \n",
       "traj_len       Car_Taxi_percent  Car           0.5     0.5        0.5   \n",
       "               Car_Car_percent   Car      0.484848     0.5        0.5   \n",
       "                                 Car_1    0.515152     0.5        0.5   \n",
       "               Car_Taxi_percent  Taxi          0.5     0.5        0.5   \n",
       "               Car_Taxi          total          30     206         22   \n",
       "               Car_Car           total          33     148         22   \n",
       "\n",
       "                                                                       \\\n",
       "                                                       200              \n",
       "                                       val_by_edge   kfold val_woedge   \n",
       "Random Forest  accuracy          mean       63.636  41.667     57.143   \n",
       "               accuracy_baseline mean       73.913  41.667     64.286   \n",
       "AdaBoost       accuracy          mean       59.091    50.0     71.429   \n",
       "               accuracy_baseline mean        60.87  33.333     57.143   \n",
       "SVM            accuracy          mean       59.091  41.667     71.429   \n",
       "               accuracy_baseline mean       69.565  33.333     35.714   \n",
       "Log Regression accuracy          mean       54.545    25.0     71.429   \n",
       "               accuracy_baseline mean        60.87    25.0     21.429   \n",
       "GBM            accuracy          mean       63.636    25.0     78.571   \n",
       "               accuracy_baseline mean       73.913  41.667     64.286   \n",
       "MLP            accuracy          mean         50.0  66.667     71.429   \n",
       "               accuracy_baseline mean        39.13    50.0     42.857   \n",
       "ensemble_model accuracy          mean       68.182     NaN     57.143   \n",
       "               accuracy_baseline mean       65.217     NaN     42.857   \n",
       "traj_len       Car_Taxi_percent  Car           0.5     0.5        0.5   \n",
       "               Car_Car_percent   Car      0.521739     0.5        0.5   \n",
       "                                 Car_1    0.478261     0.5        0.5   \n",
       "               Car_Taxi_percent  Taxi          0.5     0.5        0.5   \n",
       "               Car_Taxi          total          22     110         14   \n",
       "               Car_Car           total          23      74         14   \n",
       "\n",
       "                                                                     \\\n",
       "                                                     250              \n",
       "                                       val_by_edge kfold val_woedge   \n",
       "Random Forest  accuracy          mean         62.5  75.0       70.0   \n",
       "               accuracy_baseline mean       64.286  50.0       40.0   \n",
       "AdaBoost       accuracy          mean         75.0  25.0       80.0   \n",
       "               accuracy_baseline mean       57.143  62.5       40.0   \n",
       "SVM            accuracy          mean         75.0  37.5       60.0   \n",
       "               accuracy_baseline mean       35.714  62.5       40.0   \n",
       "Log Regression accuracy          mean         75.0  50.0       90.0   \n",
       "               accuracy_baseline mean       21.429  50.0       30.0   \n",
       "GBM            accuracy          mean         75.0  87.5      100.0   \n",
       "               accuracy_baseline mean       64.286  25.0       50.0   \n",
       "MLP            accuracy          mean        68.75  50.0       60.0   \n",
       "               accuracy_baseline mean       42.857  75.0       50.0   \n",
       "ensemble_model accuracy          mean         62.5   NaN       80.0   \n",
       "               accuracy_baseline mean       42.857   NaN       40.0   \n",
       "traj_len       Car_Taxi_percent  Car        0.4375   0.5        0.5   \n",
       "               Car_Car_percent   Car           0.5   0.5        0.5   \n",
       "                                 Car_1         0.5   0.5        0.5   \n",
       "               Car_Taxi_percent  Taxi       0.5625   0.5        0.5   \n",
       "               Car_Taxi          total          16    66         10   \n",
       "               Car_Car           total          14    52         10   \n",
       "\n",
       "                                                    \n",
       "                                                    \n",
       "                                       val_by_edge  \n",
       "Random Forest  accuracy          mean       61.538  \n",
       "               accuracy_baseline mean         40.0  \n",
       "AdaBoost       accuracy          mean       61.538  \n",
       "               accuracy_baseline mean         40.0  \n",
       "SVM            accuracy          mean       53.846  \n",
       "               accuracy_baseline mean         40.0  \n",
       "Log Regression accuracy          mean       69.231  \n",
       "               accuracy_baseline mean         30.0  \n",
       "GBM            accuracy          mean       92.308  \n",
       "               accuracy_baseline mean         50.0  \n",
       "MLP            accuracy          mean       53.846  \n",
       "               accuracy_baseline mean         50.0  \n",
       "ensemble_model accuracy          mean       69.231  \n",
       "               accuracy_baseline mean         40.0  \n",
       "traj_len       Car_Taxi_percent  Car      0.461538  \n",
       "               Car_Car_percent   Car           0.5  \n",
       "                                 Car_1         0.5  \n",
       "               Car_Taxi_percent  Taxi     0.538462  \n",
       "               Car_Taxi          total          13  \n",
       "               Car_Car           total          10  \n",
       "\n",
       "[20 rows x 60 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy results\n",
    "df_acc.loc[(slice(None),slice(None),['mean','Car','Car_1','Taxi','total']),(list(range(1,6)),slice(None),slice(None))]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "72326583629048dad8c9a913f12cb6cad5a38ceace067d86c7872c2b0df37259"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
