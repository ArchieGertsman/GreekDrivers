{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "nervous-repository",
   "metadata": {},
   "source": [
    "classical_models.ipynb\n",
    "\n",
    "by: Archie Gertsman (arkadiy2@illinois.edu)\n",
    "Lloyd Fernandes (lloydf2@illinois.edu)\n",
    "\n",
    "Project director: Richard Sowers\n",
    "\n",
    "r-sowers@illinois.eduhttps://publish.illinois.edu/r-sowers/\n",
    "\n",
    "Copyright 2019 University of Illinois Board of Trustees. All Rights Reserved. Licensed under the MIT license\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "combined-dairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "contrary-revision",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../Lib/')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from feature_eng import split_trajectories\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from time import time\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from IPython.display import display\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE\n",
    "from model_functions import *\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "killing-mortgage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>speed</th>\n",
       "      <th>lon_acc</th>\n",
       "      <th>lat_acc</th>\n",
       "      <th>type</th>\n",
       "      <th>traveled_d</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>bearing</th>\n",
       "      <th>nearest_edge_start_node</th>\n",
       "      <th>...</th>\n",
       "      <th>vehicle_density</th>\n",
       "      <th>avg_surr_speed</th>\n",
       "      <th>edge_bearing</th>\n",
       "      <th>acc_edge</th>\n",
       "      <th>acc_per_edge</th>\n",
       "      <th>xtrack_diff</th>\n",
       "      <th>xtrack_diff_sq</th>\n",
       "      <th>acc_edge_sq</th>\n",
       "      <th>acc_per_edge_sq</th>\n",
       "      <th>vehicle_density_by_lane</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file_name</th>\n",
       "      <th>id</th>\n",
       "      <th>edge_id</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">4_1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">250699362_250699984</th>\n",
       "      <th>42.00</th>\n",
       "      <td>37.982746</td>\n",
       "      <td>23.732961</td>\n",
       "      <td>11.9046</td>\n",
       "      <td>-0.1145</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>Taxi</td>\n",
       "      <td>182.37</td>\n",
       "      <td>9.740748</td>\n",
       "      <td>1.570795</td>\n",
       "      <td>250699362</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>10.464171</td>\n",
       "      <td>-2.83013</td>\n",
       "      <td>0.113220</td>\n",
       "      <td>0.021953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012819</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>1.296296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42.04</th>\n",
       "      <td>37.982746</td>\n",
       "      <td>23.732963</td>\n",
       "      <td>11.8975</td>\n",
       "      <td>-0.1007</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>Taxi</td>\n",
       "      <td>182.37</td>\n",
       "      <td>9.740748</td>\n",
       "      <td>0.168572</td>\n",
       "      <td>250699362</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>10.457843</td>\n",
       "      <td>-2.83013</td>\n",
       "      <td>0.100360</td>\n",
       "      <td>0.016867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010072</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>1.296296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42.08</th>\n",
       "      <td>37.982747</td>\n",
       "      <td>23.732964</td>\n",
       "      <td>11.8919</td>\n",
       "      <td>-0.0918</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>Taxi</td>\n",
       "      <td>182.37</td>\n",
       "      <td>9.740748</td>\n",
       "      <td>0.168573</td>\n",
       "      <td>250699362</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>10.452857</td>\n",
       "      <td>-2.83013</td>\n",
       "      <td>0.092194</td>\n",
       "      <td>0.013188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>1.296296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42.12</th>\n",
       "      <td>37.982748</td>\n",
       "      <td>23.732965</td>\n",
       "      <td>11.8871</td>\n",
       "      <td>-0.0869</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>Taxi</td>\n",
       "      <td>182.37</td>\n",
       "      <td>9.740748</td>\n",
       "      <td>1.570796</td>\n",
       "      <td>250699362</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>10.448586</td>\n",
       "      <td>-2.83013</td>\n",
       "      <td>0.087837</td>\n",
       "      <td>0.010734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007715</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>1.296296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42.16</th>\n",
       "      <td>37.982748</td>\n",
       "      <td>23.732966</td>\n",
       "      <td>11.8831</td>\n",
       "      <td>-0.0784</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>Taxi</td>\n",
       "      <td>182.37</td>\n",
       "      <td>9.740748</td>\n",
       "      <td>0.328080</td>\n",
       "      <td>250699362</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>10.444986</td>\n",
       "      <td>-2.83013</td>\n",
       "      <td>0.080021</td>\n",
       "      <td>0.007273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006403</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>1.296296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              lat        lon    speed  \\\n",
       "file_name id edge_id             time                                   \n",
       "4_1       1  250699362_250699984 42.00  37.982746  23.732961  11.9046   \n",
       "                                 42.04  37.982746  23.732963  11.8975   \n",
       "                                 42.08  37.982747  23.732964  11.8919   \n",
       "                                 42.12  37.982748  23.732965  11.8871   \n",
       "                                 42.16  37.982748  23.732966  11.8831   \n",
       "\n",
       "                                        lon_acc  lat_acc  type  traveled_d  \\\n",
       "file_name id edge_id             time                                        \n",
       "4_1       1  250699362_250699984 42.00  -0.1145   0.0138  Taxi      182.37   \n",
       "                                 42.04  -0.1007   0.0147  Taxi      182.37   \n",
       "                                 42.08  -0.0918   0.0157  Taxi      182.37   \n",
       "                                 42.12  -0.0869   0.0167  Taxi      182.37   \n",
       "                                 42.16  -0.0784   0.0176  Taxi      182.37   \n",
       "\n",
       "                                        avg_speed   bearing  \\\n",
       "file_name id edge_id             time                         \n",
       "4_1       1  250699362_250699984 42.00   9.740748  1.570795   \n",
       "                                 42.04   9.740748  0.168572   \n",
       "                                 42.08   9.740748  0.168573   \n",
       "                                 42.12   9.740748  1.570796   \n",
       "                                 42.16   9.740748  0.328080   \n",
       "\n",
       "                                        nearest_edge_start_node  ...  \\\n",
       "file_name id edge_id             time                            ...   \n",
       "4_1       1  250699362_250699984 42.00                250699362  ...   \n",
       "                                 42.04                250699362  ...   \n",
       "                                 42.08                250699362  ...   \n",
       "                                 42.12                250699362  ...   \n",
       "                                 42.16                250699362  ...   \n",
       "\n",
       "                                        vehicle_density  avg_surr_speed  \\\n",
       "file_name id edge_id             time                                     \n",
       "4_1       1  250699362_250699984 42.00                7       10.464171   \n",
       "                                 42.04                7       10.457843   \n",
       "                                 42.08                7       10.452857   \n",
       "                                 42.12                7       10.448586   \n",
       "                                 42.16                7       10.444986   \n",
       "\n",
       "                                        edge_bearing  acc_edge  acc_per_edge  \\\n",
       "file_name id edge_id             time                                          \n",
       "4_1       1  250699362_250699984 42.00      -2.83013  0.113220      0.021953   \n",
       "                                 42.04      -2.83013  0.100360      0.016867   \n",
       "                                 42.08      -2.83013  0.092194      0.013188   \n",
       "                                 42.12      -2.83013  0.087837      0.010734   \n",
       "                                 42.16      -2.83013  0.080021      0.007273   \n",
       "\n",
       "                                        xtrack_diff  xtrack_diff_sq  \\\n",
       "file_name id edge_id             time                                 \n",
       "4_1       1  250699362_250699984 42.00          0.0             0.0   \n",
       "                                 42.04          0.0             0.0   \n",
       "                                 42.08          0.0             0.0   \n",
       "                                 42.12          0.0             0.0   \n",
       "                                 42.16          0.0             0.0   \n",
       "\n",
       "                                        acc_edge_sq  acc_per_edge_sq  \\\n",
       "file_name id edge_id             time                                  \n",
       "4_1       1  250699362_250699984 42.00     0.012819         0.000482   \n",
       "                                 42.04     0.010072         0.000284   \n",
       "                                 42.08     0.008500         0.000174   \n",
       "                                 42.12     0.007715         0.000115   \n",
       "                                 42.16     0.006403         0.000053   \n",
       "\n",
       "                                        vehicle_density_by_lane  \n",
       "file_name id edge_id             time                            \n",
       "4_1       1  250699362_250699984 42.00                 1.296296  \n",
       "                                 42.04                 1.296296  \n",
       "                                 42.08                 1.296296  \n",
       "                                 42.12                 1.296296  \n",
       "                                 42.16                 1.296296  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('block4_updated.pkl') \n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-identifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def __xtrack_dist_diff(df):\n",
    "#     \"\"\"splits a vehicle trajectory into smaller trajectories of fixed size and removes\n",
    "#     the last (len(df) mod size) rows\n",
    "#     \"\"\"\n",
    "\n",
    "#     df['xtrack_diff'] = df.xtrack_dist \\\n",
    "#     .groupby(df.index.names[-1]) \\\n",
    "#     .apply(lambda x: (x - x.shift(-1)).fillna(0))\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# df = df.groupby(['file_name','id','edge_id'], as_index=False, group_keys=False) \\\n",
    "#             .apply(__xtrack_dist_diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "legislative-stock",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial parameters\n",
    "\n",
    "models = {\n",
    "        'Random Forest': Pipeline([('scaler', StandardScaler()), ('rf', RandomForestClassifier())]),\n",
    "        'AdaBoost':Pipeline([('scaler', StandardScaler()), ('abc', AdaBoostClassifier())]) ,\n",
    "        'SVM': Pipeline([('scaler', StandardScaler()), ('svc', SVC(max_iter=10000,probability = True))]) ,\n",
    "        'Log Regression': Pipeline([('scaler', StandardScaler()), ('lr', LogisticRegression(max_iter=10000))]) ,\n",
    "        'GBM': Pipeline([('scaler', StandardScaler()), ('gbm', GradientBoostingClassifier())]),\n",
    "        'MLP': Pipeline([('scaler', StandardScaler()), ('mlp', MLPClassifier(hidden_layer_sizes = (250,100,25),max_iter=1000,\\\n",
    "                                                                             learning_rate = 'adaptive',early_stopping = True,n_iter_no_change = 10))])                 \n",
    "        }\n",
    "\n",
    "agg_dict = {\n",
    "            'xtrack_diff': ['mean','std'],\n",
    "            'xtrack_dist': ['mean','std'],\n",
    "            'avg_surr_speed': ['mean','std'],\n",
    "            'lanes':['mean'],\n",
    "            'len':['mean'],\n",
    "            'speed':['mean','std'],\n",
    "            'speed_bool': ['count','sum'],\n",
    "            'acc_edge': ['mean','std'],\n",
    "            'acc_per_edge': ['mean','std']\n",
    "            }\n",
    "\n",
    "features_to_select = 10\n",
    "df_acc = pd.DataFrame(index=pd.MultiIndex.from_product([models.keys(),['f1_score','accuracy'], ['mean']]))\n",
    "overlap = 0.7\n",
    "min_movement_limit = 1\n",
    "speed_limit = 0\n",
    "k = 5\n",
    "test_ratio = 0.2\n",
    "validation_ratio = 0.2\n",
    "kf = StratifiedKFold(n_splits=k, shuffle=True)\n",
    "accs = np.zeros(k)\n",
    "f1 = np.zeros(k)\n",
    "\n",
    "traj_lens = np.arange(50,300, step=50)\n",
    "df_acc = pd.DataFrame(columns = pd.MultiIndex.from_product([[1],traj_lens,['val','test_voting_mean','test_voting_model']]), \\\n",
    "                      index=pd.MultiIndex.from_product([models.keys(),['accuracy','accuracy_baseline'], ['mean']]))\n",
    "\n",
    "ensemble_models = {\n",
    "                    'ensemble_2': ensemble(2,'val'),\n",
    "                   'ensemble_3': ensemble(3,'val'),\n",
    "                   'ensemble_5': ensemble(5,'val')\n",
    "                  }\n",
    "\n",
    "\n",
    "validation_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "pca = PCA(n_components=5)\n",
    "is_pca = False\n",
    "vehicle_density = 1\n",
    "is_log_model_voting = True\n",
    "\n",
    "\n",
    "\n",
    "df['xtrack_diff_sq'] = df['xtrack_diff']**2\n",
    "df['acc_edge_sq'] = df['acc_edge']**2\n",
    "df['acc_per_edge_sq'] = df['acc_per_edge']**2\n",
    "df['vehicle_density_by_lane'] = df['vehicle_density']/df['lanes']\n",
    "\n",
    "# agg_dict = {'xtrack_diff': ['mean','std','skew',pd.DataFrame.kurt],\n",
    "#             'xtrack_dist': ['mean','std','skew',pd.DataFrame.kurt],\n",
    "#             'avg_surr_speed': ['mean','std','skew',pd.DataFrame.kurt],\n",
    "#             'lanes':['mean'],\n",
    "#             'len':['mean'],\n",
    "#             'speed':['mean','std','skew',pd.DataFrame.kurt],\n",
    "#             'acc_edge': ['mean','std','skew',pd.DataFrame.kurt],\n",
    "#             'acc_per_edge': ['mean','std','skew',pd.DataFrame.kurt],\n",
    "#             'xtrack_diff_sq': ['mean','std','skew',pd.DataFrame.kurt],\n",
    "#             'acc_edge_sq': ['mean','std','skew',pd.DataFrame.kurt],\n",
    "#             'acc_per_edge_sq': ['mean','std','skew',pd.DataFrame.kurt],\n",
    "#             'vehicle_density_by_lane':['mean','std','skew',pd.DataFrame.kurt] }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-assessment",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('block4_updated.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "weighted-eagle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_no_of_vehicle(df,X,vehicle,vehicle_density,traj_len,column):\n",
    "    \n",
    "    df.loc[('traj_len','Car_'+vehicle,'total'), (vehicle_density,traj_len,column)] = len(X)\n",
    "    df.loc[('traj_len','Car_'+vehicle+'_percent','Car'), (vehicle_density,traj_len,column)] = sum(X == 'Car')/len(X)\n",
    "    df.loc[('traj_len','Car_'+vehicle+'_percent',vehicle), (vehicle_density,traj_len,column)] = sum(X == vehicle)/ len(X)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-cache",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with traj_len =  50\n",
      "No of trajectories:  41805\n",
      "No of Car trajectories:  20914\n",
      "No of Taxi trajectories:  20891\n",
      "\n",
      "\n",
      "with traj_len =  100\n",
      "No of trajectories:  17510\n",
      "No of Car trajectories:  8761\n",
      "No of Taxi trajectories:  8749\n",
      "\n",
      "\n",
      "with traj_len =  150\n",
      "No of trajectories:  9920\n",
      "No of Car trajectories:  4964\n",
      "No of Taxi trajectories:  4956\n",
      "\n",
      "\n",
      "with traj_len =  200\n",
      "No of trajectories:  6294\n",
      "No of Car trajectories:  3147\n",
      "No of Taxi trajectories:  3147\n",
      "\n",
      "\n",
      "with traj_len =  250\n",
      "No of trajectories:  4257\n",
      "No of Car trajectories:  2173\n",
      "No of Taxi trajectories:  2084\n",
      "\n",
      "\n",
      "with traj_len =  50\n",
      "No of trajectories:  36964\n",
      "No of Car trajectories:  18482\n",
      "No of Car_1 trajectories:  18482\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Car and Taxi classification\n",
    "\n",
    "for vehicle in ['Taxi','Car_1']:\n",
    "    \n",
    "    if vehicle == 'Car_1':\n",
    "        df_type = df[df.type == 'Car']\n",
    "        accuracy_metric = 'accuracy_baseline'\n",
    "        \n",
    "    else : \n",
    "        df_type = df.copy()\n",
    "        accuracy_metric = 'accuracy'\n",
    "        \n",
    "    for traj_len in traj_lens:\n",
    "\n",
    "        df_filtered = df_type.groupby(df_type.index.names[:-1]) \\\n",
    "                .filter(lambda grp: (len(grp) >= traj_len) )\n",
    "        \n",
    "        df_filtered['speed_bool'] = (df_filtered['speed']>speed_limit).astype(int)\n",
    "        \n",
    "        if vehicle == 'Car_1':\n",
    "            #sample 50% of cars and label them as car_1\n",
    "            df_index = df_filtered.reset_index()[['file_name','id']].drop_duplicates()\n",
    "            df_filtered.loc[df_filtered.reset_index(['edge_id', 'time'],drop = True).index.isin(df_index.sample(frac = 0.5).set_index(['file_name','id']).index),'type']=vehicle\n",
    " \n",
    "        df_train_val,df_test = split_train_test(df_filtered,validation_ratio)\n",
    "        df_train,df_val = split_train_test(df_train_val,test_ratio)\n",
    "\n",
    "        #aggregate trajectories\n",
    "        #to train models\n",
    "        X_train,y_train = get_xy(df_train,overlap = overlap,traj_len = traj_len,agg_dict = agg_dict,outlier_limit = 1,balance = 'by_edge')\n",
    "        #to pick better performing models\n",
    "        X_val,y_val = get_xy(df_val,overlap = overlap,traj_len = traj_len,agg_dict = agg_dict,balance = 'by_type')\n",
    "        #to train voting model\n",
    "        X_val_voting,y_val_voting = get_xy(df_val,overlap = overlap,traj_len = traj_len,agg_dict = agg_dict)\n",
    "        #to test ensemble and voting model\n",
    "        X_test,y_test = get_xy(df_test,overlap = overlap,traj_len = traj_len,agg_dict = agg_dict)\n",
    "\n",
    "        #pca to downsample aggregate features\n",
    "        if is_pca:\n",
    "            pca.fit(X_train)\n",
    "            X_test_voting = pd.DataFrame(data = pca.transform(X_test_voting),index = X_test_voting.index)\n",
    "            X_train = pd.DataFrame(data = pca.transform(X_train),index = X_train.index)\n",
    "            X_test = pd.DataFrame(data = pca.transform(X_test),index = X_test.index)\n",
    "            X_val = pd.DataFrame(data = pca.transform(X_val),index = X_val.index)\n",
    "\n",
    "        print(\"with traj_len = \",traj_len)\n",
    "        print(\"No of trajectories: \",len(X_train))\n",
    "        print(\"No of Car trajectories: \",sum(y_train == 'Car'))\n",
    "        print(\"No of \"+vehicle+\" trajectories: \",sum(y_train == vehicle))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        #fill number of cars and taxis/cars and car_1's in the result dataframe (df_acc)\n",
    "        df_acc = fill_no_of_vehicle(df_acc,y_test,vehicle,vehicle_density,traj_len,'val')\n",
    "        \n",
    "        id_list = y_val.reset_index(['edge_id'],drop = True).reset_index().drop_duplicates()\n",
    "        df_acc = fill_no_of_vehicle(df_acc,id_list.type,vehicle,vehicle_density,traj_len,'test_voting_mean')\n",
    "        df_acc = fill_no_of_vehicle(df_acc,id_list.type,vehicle,vehicle_density,traj_len,'test_voting_model')\n",
    "        \n",
    "        model_dict = {}\n",
    "        \n",
    "        # fit different models\n",
    "        for name, model in models.items():\n",
    "\n",
    "            #fit the model on training set\n",
    "            model.fit(X_train,y_train)\n",
    "\n",
    "            #test the model on validation set consisting of trajectories and save accuracy estimate as test (this accuracy estimate will be used to find ensemble) \n",
    "            val_accs,_ = basic_accuracy(X_val,y_val,model)                                   \n",
    "            df_acc.loc[(name, accuracy_metric,'mean'),  (vehicle_density,traj_len,'val')] = round(100*val_accs, 3)\n",
    "            \n",
    "            #find accuracy of the model on test set by voting among trajectories in an id using mean\n",
    "            test_accs,_ = voting_accuracy(X_test,y_test, model,predict_proba = True)\n",
    "            df_acc.loc[(name, accuracy_metric,'mean'), (vehicle_density,traj_len,'test_voting_mean')] = round(100*test_accs, 3)\n",
    "            #plt.savefig(\"traj_len\"+str(traj_len)+name+\".png\")\n",
    "            \n",
    "            #train voting model for voting among trajectories using the validation set with equal number of vehicle id's\n",
    "            voting_m = voting_model(model,X_val_voting,y_val_voting)\n",
    "            #find the accuracy of the model on validation set with voting using logistic regression\n",
    "            val_accs,_ = voting_m.accuracy(X_test,y_test)#, voting_m, predict_proba = False)\n",
    "            df_acc.loc[(name, accuracy_metric,'mean'), (vehicle_density,traj_len,'test_voting_model')] = round(100*val_accs, 3)\n",
    "\n",
    "            #save model in dictionary for ensemble\n",
    "            model_dict[name] = model\n",
    "\n",
    "        for name,ensemble_model in ensemble_models.items():\n",
    "            #generate ensembles with 2,3 and 5 models\n",
    "            ensemble_model.find_ensemble(df_acc,traj_len,vehicle_density,True)\n",
    "            ensemble_model.fit(X_train,y_train,model_dict)\n",
    "\n",
    "            #test accuracy of ensembles on test set\n",
    "            test_accs,_ = voting_accuracy(X_test,y_test, ensemble_model)\n",
    "            df_acc.loc[(name, accuracy_metric,'mean'), (vehicle_density,traj_len,'test_voting_mean')] = round(100*test_accs, 3)\n",
    "\n",
    "            #test accuracy of ensembles on validation using voting_model (trained on validation set)\n",
    "            voting_m = voting_model(ensemble_model,X_val_voting,y_val_voting)\n",
    "            test_accs,_ = voting_m.accuracy(X_test,y_test)\n",
    "            df_acc.loc[(name, accuracy_metric,'mean'), (vehicle_density,traj_len,'test_voting_model')] = round(100*test_accs, 3)\n",
    "\n",
    "df_acc.fillna(0,inplace = True)\n",
    "\n",
    "df_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "increased-child",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-b2eb5d918ba3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#df_acc.sort_index()#.to_csv(\"accuracy_block4_100_traj_len.csv\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0m__accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name '__accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "#df_acc.sort_index()#.to_csv(\"accuracy_block4_100_traj_len.csv\")\n",
    "__accuracy(y_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-range",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
