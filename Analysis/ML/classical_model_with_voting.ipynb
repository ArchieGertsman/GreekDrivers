{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"classical_models.ipynb\n",
    "by: Archie Gertsman (arkadiy2@illinois.edu)\n",
    "Project director: Richard Sowers\n",
    "r-sowers@illinois.eduhttps://publish.illinois.edu/r-sowers/\n",
    "Copyright 2019 University of Illinois Board of Trustees. All Rights Reserved. Licensed under the MIT license\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from feature_eng import split_trajectories\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>speed</th>\n",
       "      <th>lon_acc</th>\n",
       "      <th>lat_acc</th>\n",
       "      <th>type</th>\n",
       "      <th>traveled_d</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>bearing</th>\n",
       "      <th>nearest_edge_start_node</th>\n",
       "      <th>...</th>\n",
       "      <th>xtrack_dist</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>edge_progress_intervals</th>\n",
       "      <th>edge_id</th>\n",
       "      <th>len</th>\n",
       "      <th>lanes</th>\n",
       "      <th>node_veh_dist</th>\n",
       "      <th>edge_seg</th>\n",
       "      <th>vehicle_density</th>\n",
       "      <th>avg_surr_speed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file_name</th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">4_1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>42.00</th>\n",
       "      <td>37.982746</td>\n",
       "      <td>23.732961</td>\n",
       "      <td>11.9046</td>\n",
       "      <td>-0.1145</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>Taxi</td>\n",
       "      <td>182.37</td>\n",
       "      <td>9.740748</td>\n",
       "      <td>1.570795</td>\n",
       "      <td>250699362</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.883401</td>\n",
       "      <td>42.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>250699362_250699984</td>\n",
       "      <td>97.581</td>\n",
       "      <td>5.4</td>\n",
       "      <td>29.814330</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>10.464171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42.04</th>\n",
       "      <td>37.982746</td>\n",
       "      <td>23.732963</td>\n",
       "      <td>11.8975</td>\n",
       "      <td>-0.1007</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>Taxi</td>\n",
       "      <td>182.37</td>\n",
       "      <td>9.740748</td>\n",
       "      <td>0.168572</td>\n",
       "      <td>250699362</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.980795</td>\n",
       "      <td>42.04</td>\n",
       "      <td>0.3</td>\n",
       "      <td>250699362_250699984</td>\n",
       "      <td>97.581</td>\n",
       "      <td>5.4</td>\n",
       "      <td>29.674830</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>10.457843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42.08</th>\n",
       "      <td>37.982747</td>\n",
       "      <td>23.732964</td>\n",
       "      <td>11.8919</td>\n",
       "      <td>-0.0918</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>Taxi</td>\n",
       "      <td>182.37</td>\n",
       "      <td>9.740748</td>\n",
       "      <td>0.168573</td>\n",
       "      <td>250699362</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.937041</td>\n",
       "      <td>42.08</td>\n",
       "      <td>0.3</td>\n",
       "      <td>250699362_250699984</td>\n",
       "      <td>97.581</td>\n",
       "      <td>5.4</td>\n",
       "      <td>29.537753</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>10.452857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42.12</th>\n",
       "      <td>37.982748</td>\n",
       "      <td>23.732965</td>\n",
       "      <td>11.8871</td>\n",
       "      <td>-0.0869</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>Taxi</td>\n",
       "      <td>182.37</td>\n",
       "      <td>9.740748</td>\n",
       "      <td>1.570796</td>\n",
       "      <td>250699362</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.893287</td>\n",
       "      <td>42.12</td>\n",
       "      <td>0.3</td>\n",
       "      <td>250699362_250699984</td>\n",
       "      <td>97.581</td>\n",
       "      <td>5.4</td>\n",
       "      <td>29.400718</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>10.448586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42.16</th>\n",
       "      <td>37.982748</td>\n",
       "      <td>23.732966</td>\n",
       "      <td>11.8831</td>\n",
       "      <td>-0.0784</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>Taxi</td>\n",
       "      <td>182.37</td>\n",
       "      <td>9.740748</td>\n",
       "      <td>0.328080</td>\n",
       "      <td>250699362</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.941984</td>\n",
       "      <td>42.16</td>\n",
       "      <td>0.3</td>\n",
       "      <td>250699362_250699984</td>\n",
       "      <td>97.581</td>\n",
       "      <td>5.4</td>\n",
       "      <td>29.330986</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>10.444986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          lat        lon    speed  lon_acc  lat_acc  type  \\\n",
       "file_name id time                                                           \n",
       "4_1       1  42.00  37.982746  23.732961  11.9046  -0.1145   0.0138  Taxi   \n",
       "             42.04  37.982746  23.732963  11.8975  -0.1007   0.0147  Taxi   \n",
       "             42.08  37.982747  23.732964  11.8919  -0.0918   0.0157  Taxi   \n",
       "             42.12  37.982748  23.732965  11.8871  -0.0869   0.0167  Taxi   \n",
       "             42.16  37.982748  23.732966  11.8831  -0.0784   0.0176  Taxi   \n",
       "\n",
       "                    traveled_d  avg_speed   bearing  nearest_edge_start_node  \\\n",
       "file_name id time                                                              \n",
       "4_1       1  42.00      182.37   9.740748  1.570795                250699362   \n",
       "             42.04      182.37   9.740748  0.168572                250699362   \n",
       "             42.08      182.37   9.740748  0.168573                250699362   \n",
       "             42.12      182.37   9.740748  1.570796                250699362   \n",
       "             42.16      182.37   9.740748  0.328080                250699362   \n",
       "\n",
       "                    ...  xtrack_dist  time_stamp  edge_progress_intervals  \\\n",
       "file_name id time   ...                                                     \n",
       "4_1       1  42.00  ...    -1.883401       42.00                      0.3   \n",
       "             42.04  ...    -1.980795       42.04                      0.3   \n",
       "             42.08  ...    -1.937041       42.08                      0.3   \n",
       "             42.12  ...    -1.893287       42.12                      0.3   \n",
       "             42.16  ...    -1.941984       42.16                      0.3   \n",
       "\n",
       "                                edge_id     len  lanes node_veh_dist  \\\n",
       "file_name id time                                                      \n",
       "4_1       1  42.00  250699362_250699984  97.581    5.4     29.814330   \n",
       "             42.04  250699362_250699984  97.581    5.4     29.674830   \n",
       "             42.08  250699362_250699984  97.581    5.4     29.537753   \n",
       "             42.12  250699362_250699984  97.581    5.4     29.400718   \n",
       "             42.16  250699362_250699984  97.581    5.4     29.330986   \n",
       "\n",
       "                    edge_seg  vehicle_density  avg_surr_speed  \n",
       "file_name id time                                              \n",
       "4_1       1  42.00       1.0                7       10.464171  \n",
       "             42.04       1.0                7       10.457843  \n",
       "             42.08       1.0                7       10.452857  \n",
       "             42.12       1.0                7       10.448586  \n",
       "             42.16       1.0                7       10.444986  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('block4_concat_lane.pkl')\n",
    "#df = pd.read_pickle('block4_edge_filter.pkl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>speed</th>\n",
       "      <th>lon_acc</th>\n",
       "      <th>lat_acc</th>\n",
       "      <th>type</th>\n",
       "      <th>traveled_d</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>bearing</th>\n",
       "      <th>nearest_edge_start_node</th>\n",
       "      <th>...</th>\n",
       "      <th>dir</th>\n",
       "      <th>xtrack_dist</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>edge_progress_intervals</th>\n",
       "      <th>len</th>\n",
       "      <th>lanes</th>\n",
       "      <th>node_veh_dist</th>\n",
       "      <th>edge_seg</th>\n",
       "      <th>vehicle_density</th>\n",
       "      <th>avg_surr_speed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file_name</th>\n",
       "      <th>id</th>\n",
       "      <th>edge_id</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">4_1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">250699362_250699984</th>\n",
       "      <th>42.00</th>\n",
       "      <td>37.982746</td>\n",
       "      <td>23.732961</td>\n",
       "      <td>11.9046</td>\n",
       "      <td>-0.1145</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>Taxi</td>\n",
       "      <td>182.37</td>\n",
       "      <td>9.740748</td>\n",
       "      <td>1.570795</td>\n",
       "      <td>250699362</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.883401</td>\n",
       "      <td>42.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>97.581</td>\n",
       "      <td>5.4</td>\n",
       "      <td>29.814330</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>10.464171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42.04</th>\n",
       "      <td>37.982746</td>\n",
       "      <td>23.732963</td>\n",
       "      <td>11.8975</td>\n",
       "      <td>-0.1007</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>Taxi</td>\n",
       "      <td>182.37</td>\n",
       "      <td>9.740748</td>\n",
       "      <td>0.168572</td>\n",
       "      <td>250699362</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.980795</td>\n",
       "      <td>42.04</td>\n",
       "      <td>0.3</td>\n",
       "      <td>97.581</td>\n",
       "      <td>5.4</td>\n",
       "      <td>29.674830</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>10.457843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42.08</th>\n",
       "      <td>37.982747</td>\n",
       "      <td>23.732964</td>\n",
       "      <td>11.8919</td>\n",
       "      <td>-0.0918</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>Taxi</td>\n",
       "      <td>182.37</td>\n",
       "      <td>9.740748</td>\n",
       "      <td>0.168573</td>\n",
       "      <td>250699362</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.937041</td>\n",
       "      <td>42.08</td>\n",
       "      <td>0.3</td>\n",
       "      <td>97.581</td>\n",
       "      <td>5.4</td>\n",
       "      <td>29.537753</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>10.452857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42.12</th>\n",
       "      <td>37.982748</td>\n",
       "      <td>23.732965</td>\n",
       "      <td>11.8871</td>\n",
       "      <td>-0.0869</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>Taxi</td>\n",
       "      <td>182.37</td>\n",
       "      <td>9.740748</td>\n",
       "      <td>1.570796</td>\n",
       "      <td>250699362</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.893287</td>\n",
       "      <td>42.12</td>\n",
       "      <td>0.3</td>\n",
       "      <td>97.581</td>\n",
       "      <td>5.4</td>\n",
       "      <td>29.400718</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>10.448586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42.16</th>\n",
       "      <td>37.982748</td>\n",
       "      <td>23.732966</td>\n",
       "      <td>11.8831</td>\n",
       "      <td>-0.0784</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>Taxi</td>\n",
       "      <td>182.37</td>\n",
       "      <td>9.740748</td>\n",
       "      <td>0.328080</td>\n",
       "      <td>250699362</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.941984</td>\n",
       "      <td>42.16</td>\n",
       "      <td>0.3</td>\n",
       "      <td>97.581</td>\n",
       "      <td>5.4</td>\n",
       "      <td>29.330986</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>10.444986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              lat        lon    speed  \\\n",
       "file_name id edge_id             time                                   \n",
       "4_1       1  250699362_250699984 42.00  37.982746  23.732961  11.9046   \n",
       "                                 42.04  37.982746  23.732963  11.8975   \n",
       "                                 42.08  37.982747  23.732964  11.8919   \n",
       "                                 42.12  37.982748  23.732965  11.8871   \n",
       "                                 42.16  37.982748  23.732966  11.8831   \n",
       "\n",
       "                                        lon_acc  lat_acc  type  traveled_d  \\\n",
       "file_name id edge_id             time                                        \n",
       "4_1       1  250699362_250699984 42.00  -0.1145   0.0138  Taxi      182.37   \n",
       "                                 42.04  -0.1007   0.0147  Taxi      182.37   \n",
       "                                 42.08  -0.0918   0.0157  Taxi      182.37   \n",
       "                                 42.12  -0.0869   0.0167  Taxi      182.37   \n",
       "                                 42.16  -0.0784   0.0176  Taxi      182.37   \n",
       "\n",
       "                                        avg_speed   bearing  \\\n",
       "file_name id edge_id             time                         \n",
       "4_1       1  250699362_250699984 42.00   9.740748  1.570795   \n",
       "                                 42.04   9.740748  0.168572   \n",
       "                                 42.08   9.740748  0.168573   \n",
       "                                 42.12   9.740748  1.570796   \n",
       "                                 42.16   9.740748  0.328080   \n",
       "\n",
       "                                        nearest_edge_start_node  ...  dir  \\\n",
       "file_name id edge_id             time                            ...        \n",
       "4_1       1  250699362_250699984 42.00                250699362  ...    0   \n",
       "                                 42.04                250699362  ...    0   \n",
       "                                 42.08                250699362  ...    0   \n",
       "                                 42.12                250699362  ...    0   \n",
       "                                 42.16                250699362  ...    0   \n",
       "\n",
       "                                        xtrack_dist  time_stamp  \\\n",
       "file_name id edge_id             time                             \n",
       "4_1       1  250699362_250699984 42.00    -1.883401       42.00   \n",
       "                                 42.04    -1.980795       42.04   \n",
       "                                 42.08    -1.937041       42.08   \n",
       "                                 42.12    -1.893287       42.12   \n",
       "                                 42.16    -1.941984       42.16   \n",
       "\n",
       "                                        edge_progress_intervals     len  \\\n",
       "file_name id edge_id             time                                     \n",
       "4_1       1  250699362_250699984 42.00                      0.3  97.581   \n",
       "                                 42.04                      0.3  97.581   \n",
       "                                 42.08                      0.3  97.581   \n",
       "                                 42.12                      0.3  97.581   \n",
       "                                 42.16                      0.3  97.581   \n",
       "\n",
       "                                        lanes  node_veh_dist  edge_seg  \\\n",
       "file_name id edge_id             time                                    \n",
       "4_1       1  250699362_250699984 42.00    5.4      29.814330       1.0   \n",
       "                                 42.04    5.4      29.674830       1.0   \n",
       "                                 42.08    5.4      29.537753       1.0   \n",
       "                                 42.12    5.4      29.400718       1.0   \n",
       "                                 42.16    5.4      29.330986       1.0   \n",
       "\n",
       "                                        vehicle_density  avg_surr_speed  \n",
       "file_name id edge_id             time                                    \n",
       "4_1       1  250699362_250699984 42.00                7       10.464171  \n",
       "                                 42.04                7       10.457843  \n",
       "                                 42.08                7       10.452857  \n",
       "                                 42.12                7       10.448586  \n",
       "                                 42.16                7       10.444986  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding edge_id to the index\n",
    "df.index = df.reset_index().set_index(['file_name','id','edge_id','time']).index\n",
    "df.drop(['edge_id'],inplace = True,axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding difference between cross track distance between adjacent rows\n",
    "def __xtrack_dist_diff(df):\n",
    "    \"\"\"splits a vehicle trajectory into smaller trajectories of fixed size and removes\n",
    "    the last (len(df) mod size) riws\n",
    "    \"\"\"\n",
    "    \n",
    "    df[\"xtrack_diff\"] = df.loc[:,['xtrack_dist']]- df.loc[:,['xtrack_dist']].shift(-1)\n",
    "    df[\"xtrack_diff\"]=df['xtrack_diff'].fillna(0)\n",
    "    return df\n",
    "\n",
    "\n",
    "df = df.groupby(['file_name','id','edge_id'], as_index=False, group_keys=False) \\\n",
    "            .apply(__xtrack_dist_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split trajectories with overlap\n",
    "def split_trajectories_overlap(df, size, overlap):\n",
    "    \"\"\"splits each vehicle's trajectory into smaller trajectories of fixed size,\n",
    "    adding another dimension to the multiindex. Data is truncated to be a multiple\n",
    "    of `size` in length. \n",
    "    Example usage:\n",
    "        df = csv_to_df('sample.csv')\n",
    "        df = split_trajectories(df, 3000)\n",
    "    \"\"\"\n",
    "    overlap = 1-overlap\n",
    "    if overlap == 0:\n",
    "        return split_trajectories(df,size)\n",
    "    else:\n",
    "        df1 = df.groupby(['id','file_name',\"edge_id\"], as_index=False, group_keys=False) \\\n",
    "                .apply(__split_vehicle, size)\n",
    "\n",
    "        for i in range(1,int(1/overlap)):\n",
    "            \"\"\" remove x rows from each group and then split the trajectory. \n",
    "            eg: say the overlap is 50% with traj_lens = 300, when i = 1, delete first 150 rows and then split trajectory from \n",
    "            150-450,450-750 etc\n",
    "            \"\"\"\n",
    "            df2 = df.groupby(['id','file_name',\"edge_id\"], as_index=False, group_keys=False) \\\n",
    "                .apply(__remove_initial_rows, int(i*overlap*size))\n",
    "            df2 = df2.groupby(['id','file_name',\"edge_id\"], as_index=False, group_keys=False) \\\n",
    "                .apply(__split_vehicle, size)\n",
    "            \n",
    "            #give different trajectory name for each overlap iteration\n",
    "            df2.index = df2.index.set_levels(df2.index.levels[3].astype(str) + '_'+str(i), level=3)\n",
    "            \n",
    "            #concatenate dataframes one below the other\n",
    "            df1 = pd.concat([df1,df2],axis = 0)\n",
    "\n",
    "        return df1\n",
    "\n",
    "def __remove_initial_rows(df,ele):\n",
    "    #if ele > number of rows, remedy the error by returning none\n",
    "    try:\n",
    "        df1 = df[ele:]\n",
    "    except TypeError:\n",
    "        df1 = None\n",
    "  \n",
    "    return df1\n",
    "\n",
    "def __split_vehicle(df, size):\n",
    "    \"\"\"splits a vehicle trajectory into smaller trajectories of fixed size and removes\n",
    "    the last (len(df) mod size) riws\n",
    "    \"\"\"\n",
    "    df2 = df.copy()\n",
    "    df2['traj'] = None\n",
    "    df2.loc[::size, 'traj'] = np.arange(len(df2[::size]), dtype=int)\n",
    "    df2['traj'].ffill(inplace=True)\n",
    "    df2.set_index('traj', append=True, inplace=True)\n",
    "    df2 = __truncate_trajectory(df2, size)\n",
    "    df2 = df2.reorder_levels([0,1,2,4,3])\n",
    "    return df2\n",
    "\n",
    "\n",
    "def __truncate_to_multiple(n, m):\n",
    "    return m * (n // m)\n",
    "\n",
    "def __truncate_trajectory(traj, size):\n",
    "    n = len(traj)\n",
    "    new_len = __truncate_to_multiple(n, size)\n",
    "    return traj[:new_len]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg(df,is_validation_set = False):\n",
    "    \n",
    "    df['xtrack_diff_sq'] = df['xtrack_diff']**2\n",
    "    df_agg = df[np.isin(df['type'], ['Car','Taxi'])] \\\n",
    "        .groupby(['file_name','id', 'edge_id','traj']).agg({\n",
    "            'xtrack_diff_sq': ['mean','std','skew','max','min',pd.DataFrame.kurt,'sum'],\n",
    "            'xtrack_diff': ['mean','std','skew',pd.DataFrame.kurt],\n",
    "            'xtrack_dist': ['mean','std','skew',pd.DataFrame.kurt],\n",
    "            'avg_surr_speed': ['mean','std','skew',pd.DataFrame.kurt],\n",
    "            'lanes':['mean'],\n",
    "            'len':['mean'],\n",
    "            'speed':['mean','std','skew',pd.DataFrame.kurt,'sum'],\n",
    "            'vehicle_density': ['mean','std','skew',pd.DataFrame.kurt],\n",
    "            'lon_acc': ['mean','std','max','min','skew', pd.DataFrame.kurt],\n",
    "            'lat_acc': ['mean','std','max','min', 'skew', pd.DataFrame.kurt],\n",
    "            'type': 'first'\n",
    "        }) \\\n",
    "        \n",
    "    df_agg.columns = ['_'.join(col) for col in df_agg.columns]\n",
    "    df_agg.speed_sum = df_agg.speed_sum*0.04\n",
    "    df_agg.rename(columns={'type_first':'type'}, inplace=True)\n",
    "    \n",
    "    if is_validation_set == False:\n",
    "        g = df_agg.groupby('type')\n",
    "        df_agg = g.apply(lambda group: group.sample(g.size().min())).reset_index(drop=True)\n",
    "        X,y = df_agg.drop('type', axis=1), df_agg['type']\n",
    "        return X,y\n",
    "    \n",
    "    else:\n",
    "        #df_agg = g.apply(lambda group: group.sample(g.size().min()))\n",
    "        X,y = df_agg.drop('type', axis=1), df_agg['type']\n",
    "        return X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_accuracy(X_train,y_train,X_test,y_test, model):\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_hat = model.predict(X_test)\n",
    "    a = y_hat==y_test\n",
    "    \n",
    "    f = f1_score((y_test == 'Car').astype(int),(y_hat == 'Car').astype(int))\n",
    "    return len(a[a==True]) / len(y_test),f\n",
    "\n",
    "def val_voting_accuracy(X_train,y_train,X_val,y_val, model,by_edge = False):\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_hat = model.predict(X_val)\n",
    "    if by_edge == False:\n",
    "        y_hat = pd.DataFrame(index = y_val.index,data = y_hat,columns = ['type'])\n",
    "\n",
    "        #predicted value for the entire trajectory would be the mode of the predicted labels\n",
    "        y_hat = y_hat.groupby(['file_name','id']).apply(lambda group: pd.Series.mode(group['type'])[0])\n",
    "        y_test = y_val.groupby(['file_name','id']).first(['type'])\n",
    "    else:\n",
    "        y_hat = pd.DataFrame(index = y_val.index,data = y_hat,columns = ['type'])\n",
    "\n",
    "        #predicted value for the entire trajectory would be the mode of the predicted labels\n",
    "        y_hat = y_hat.groupby(['file_name','id','edge_id']).apply(lambda group: pd.Series.mode(group['type'])[0])\n",
    "        y_test = y_val.groupby(['file_name','id','edge_id']).first(['type'])\n",
    "\n",
    "    a = y_hat==y_test\n",
    "   \n",
    "    f = f1_score((y_test == 'Car').astype(int),(y_hat == 'Car').astype(int))\n",
    "    return len(a[a==True]) / len(y_test),f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def validation_set(df,test_size):\n",
    "    \"\"\"dataframe is split based on their vehicle id's\"\"\"\n",
    "    df1 = df.reset_index()[[\"file_name\",'id','type']].drop_duplicates()\n",
    "    X = df1[[\"file_name\",\"id\"]]\n",
    "    y = df1['type']\n",
    "    X_train,X_test,_,y_test = train_test_split(X, y, test_size=test_size, random_state=4, stratify=y) \n",
    "    df_train = df[df.index.droplevel(['time','edge_id']).isin(X_train.set_index(['file_name','id']).index)]\n",
    "    X_test['type'] = y_test\n",
    "    g = X_test.groupby('type')\n",
    "    X_test = g.apply(lambda group: group.sample(g.size().min())).reset_index(drop = True)\n",
    "    df_test = df[df.index.droplevel(['time','edge_id']).isin(X_test.set_index(['file_name','id']).index)]\n",
    "    print(\"No of Cars in validation set %d, No of Taxis in validation set %d\" % (sum(X_test['type'] == 'Car'),sum(X_test['type'] == 'Taxi')))\n",
    "    return df_train,df_test\n",
    "\n",
    "def process_traj(df2,traj_len,overlap,speed_limit,min_movement_limit,vehicle_density_limit = None):\n",
    "    \"\"\" the trajectories are split into smaller trajectories of fixed size traj_len\"\"\"\n",
    "    df2 = split_trajectories_overlap(df2, traj_len, overlap)\n",
    "    df3 = df2.reset_index()[[\"id\",\"file_name\",\"edge_id\",\"traj\",\"speed\"]]\n",
    "    \n",
    "    #consider only those trajectories which move at a minimum speed of speed_limit for min_movement_limit%\n",
    "    df3[\"speed_bool\"]= df3[\"speed\"]>speed_limit\n",
    "    df3 = df3.groupby([\"file_name\",\"id\",\"edge_id\",\"traj\"]).sum([\"speed_bool\"])\n",
    "    df2 = df2[df2.index.droplevel(4).isin(df3[df3.speed_bool >= traj_len*min_movement_limit].index.to_list())]\n",
    "    \n",
    "    #filter trajectory by minimum vehicle_density_limit\n",
    "    if vehicle_density_limit == None:\n",
    "        return df2\n",
    "    \n",
    "    else:\n",
    "        df3 = df2.reset_index()[[\"id\",\"file_name\",\"edge_id\",\"traj\",\"vehicle_density\"]]\n",
    "        df3 = df3.groupby([\"file_name\",\"id\",\"edge_id\",\"traj\"]).mean([\"vehicle_density\"])\n",
    "        df2 = df2[df2.index.droplevel(4).isin(df3[df3.vehicle_density >= vehicle_density_limit].index.to_list())]\n",
    "        \n",
    "        return df2\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Cars in validation set 105, No of Taxis in validation set 105\n",
      "No of trajectories:  2834\n",
      "Random Forest complete.\n",
      "AdaBoost complete.\n",
      "SVM complete.\n",
      "Log Regression complete.\n",
      "trajectory length 300 complete.\n",
      "No of Cars in validation set 95, No of Taxis in validation set 95\n",
      "No of trajectories:  2058\n",
      "Random Forest complete.\n",
      "AdaBoost complete.\n",
      "SVM complete.\n",
      "Log Regression complete.\n",
      "trajectory length 350 complete.\n",
      "No of Cars in validation set 85, No of Taxis in validation set 85\n",
      "No of trajectories:  1536\n",
      "Random Forest complete.\n",
      "AdaBoost complete.\n",
      "SVM complete.\n",
      "Log Regression complete.\n",
      "trajectory length 400 complete.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>300_kfold</th>\n",
       "      <th>300_val_woedge</th>\n",
       "      <th>300_val_by_edge</th>\n",
       "      <th>350_kfold</th>\n",
       "      <th>350_val_woedge</th>\n",
       "      <th>350_val_by_edge</th>\n",
       "      <th>400_kfold</th>\n",
       "      <th>400_val_woedge</th>\n",
       "      <th>400_val_by_edge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Random Forest</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">f1_score</th>\n",
       "      <th>mean</th>\n",
       "      <td>61.249</td>\n",
       "      <td>61.611000</td>\n",
       "      <td>58.824000</td>\n",
       "      <td>62.608</td>\n",
       "      <td>57.923000</td>\n",
       "      <td>54.980000</td>\n",
       "      <td>58.631</td>\n",
       "      <td>56.757000</td>\n",
       "      <td>53.333000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.346</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">accuracy</th>\n",
       "      <th>mean</th>\n",
       "      <td>62.173</td>\n",
       "      <td>60.099000</td>\n",
       "      <td>56.818000</td>\n",
       "      <td>64.189</td>\n",
       "      <td>56.497000</td>\n",
       "      <td>54.980000</td>\n",
       "      <td>60.413</td>\n",
       "      <td>56.463000</td>\n",
       "      <td>54.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.886</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">AdaBoost</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">f1_score</th>\n",
       "      <th>mean</th>\n",
       "      <td>58.278</td>\n",
       "      <td>61.165000</td>\n",
       "      <td>60.256000</td>\n",
       "      <td>61.518</td>\n",
       "      <td>58.140000</td>\n",
       "      <td>56.432000</td>\n",
       "      <td>56.080</td>\n",
       "      <td>51.471000</td>\n",
       "      <td>52.747000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.463</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">accuracy</th>\n",
       "      <th>mean</th>\n",
       "      <td>60.339</td>\n",
       "      <td>60.591000</td>\n",
       "      <td>59.740000</td>\n",
       "      <td>63.314</td>\n",
       "      <td>59.322000</td>\n",
       "      <td>58.167000</td>\n",
       "      <td>58.141</td>\n",
       "      <td>55.102000</td>\n",
       "      <td>57.426000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.027</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">SVM</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">f1_score</th>\n",
       "      <th>mean</th>\n",
       "      <td>55.334</td>\n",
       "      <td>54.737000</td>\n",
       "      <td>54.417000</td>\n",
       "      <td>57.992</td>\n",
       "      <td>52.500000</td>\n",
       "      <td>47.847000</td>\n",
       "      <td>52.883</td>\n",
       "      <td>53.226000</td>\n",
       "      <td>51.534000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.823</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.682</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">accuracy</th>\n",
       "      <th>mean</th>\n",
       "      <td>61.820</td>\n",
       "      <td>57.635000</td>\n",
       "      <td>58.117000</td>\n",
       "      <td>63.267</td>\n",
       "      <td>57.062000</td>\n",
       "      <td>56.574000</td>\n",
       "      <td>59.830</td>\n",
       "      <td>60.544000</td>\n",
       "      <td>60.891000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Log Regression</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">f1_score</th>\n",
       "      <th>mean</th>\n",
       "      <td>55.032</td>\n",
       "      <td>49.746000</td>\n",
       "      <td>50.676000</td>\n",
       "      <td>53.678</td>\n",
       "      <td>50.314000</td>\n",
       "      <td>49.778000</td>\n",
       "      <td>53.030</td>\n",
       "      <td>50.769000</td>\n",
       "      <td>47.619000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.191</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.446</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">accuracy</th>\n",
       "      <th>mean</th>\n",
       "      <td>57.869</td>\n",
       "      <td>51.232000</td>\n",
       "      <td>52.597000</td>\n",
       "      <td>58.065</td>\n",
       "      <td>55.367000</td>\n",
       "      <td>54.980000</td>\n",
       "      <td>58.009</td>\n",
       "      <td>56.463000</td>\n",
       "      <td>56.436000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">traj_len</th>\n",
       "      <th>traj_len</th>\n",
       "      <th>total</th>\n",
       "      <td>2834.000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>2058.000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>1536.000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>202.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">percent</th>\n",
       "      <th>Car</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.487685</td>\n",
       "      <td>0.496753</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.491525</td>\n",
       "      <td>0.478088</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.482993</td>\n",
       "      <td>0.465347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taxi</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.512315</td>\n",
       "      <td>0.503247</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.508475</td>\n",
       "      <td>0.521912</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.517007</td>\n",
       "      <td>0.534653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               300_kfold  300_val_woedge  300_val_by_edge  \\\n",
       "Random Forest  f1_score mean      61.249       61.611000        58.824000   \n",
       "                        std        2.346             NaN              NaN   \n",
       "               accuracy mean      62.173       60.099000        56.818000   \n",
       "                        std        1.546             NaN              NaN   \n",
       "AdaBoost       f1_score mean      58.278       61.165000        60.256000   \n",
       "                        std        0.946             NaN              NaN   \n",
       "               accuracy mean      60.339       60.591000        59.740000   \n",
       "                        std        1.317             NaN              NaN   \n",
       "SVM            f1_score mean      55.334       54.737000        54.417000   \n",
       "                        std        2.823             NaN              NaN   \n",
       "               accuracy mean      61.820       57.635000        58.117000   \n",
       "                        std        2.095             NaN              NaN   \n",
       "Log Regression f1_score mean      55.032       49.746000        50.676000   \n",
       "                        std        1.191             NaN              NaN   \n",
       "               accuracy mean      57.869       51.232000        52.597000   \n",
       "                        std        1.304             NaN              NaN   \n",
       "traj_len       traj_len total   2834.000      203.000000       308.000000   \n",
       "               percent  Car        0.500        0.487685         0.496753   \n",
       "                        Taxi       0.500        0.512315         0.503247   \n",
       "\n",
       "                               350_kfold  350_val_woedge  350_val_by_edge  \\\n",
       "Random Forest  f1_score mean      62.608       57.923000        54.980000   \n",
       "                        std        2.720             NaN              NaN   \n",
       "               accuracy mean      64.189       56.497000        54.980000   \n",
       "                        std        1.723             NaN              NaN   \n",
       "AdaBoost       f1_score mean      61.518       58.140000        56.432000   \n",
       "                        std        1.310             NaN              NaN   \n",
       "               accuracy mean      63.314       59.322000        58.167000   \n",
       "                        std        1.027             NaN              NaN   \n",
       "SVM            f1_score mean      57.992       52.500000        47.847000   \n",
       "                        std        3.813             NaN              NaN   \n",
       "               accuracy mean      63.267       57.062000        56.574000   \n",
       "                        std        2.905             NaN              NaN   \n",
       "Log Regression f1_score mean      53.678       50.314000        49.778000   \n",
       "                        std        3.262             NaN              NaN   \n",
       "               accuracy mean      58.065       55.367000        54.980000   \n",
       "                        std        1.797             NaN              NaN   \n",
       "traj_len       traj_len total   2058.000      177.000000       251.000000   \n",
       "               percent  Car        0.500        0.491525         0.478088   \n",
       "                        Taxi       0.500        0.508475         0.521912   \n",
       "\n",
       "                               400_kfold  400_val_woedge  400_val_by_edge  \n",
       "Random Forest  f1_score mean      58.631       56.757000        53.333000  \n",
       "                        std        4.567             NaN              NaN  \n",
       "               accuracy mean      60.413       56.463000        54.950000  \n",
       "                        std        3.886             NaN              NaN  \n",
       "AdaBoost       f1_score mean      56.080       51.471000        52.747000  \n",
       "                        std        2.463             NaN              NaN  \n",
       "               accuracy mean      58.141       55.102000        57.426000  \n",
       "                        std        3.052             NaN              NaN  \n",
       "SVM            f1_score mean      52.883       53.226000        51.534000  \n",
       "                        std        4.682             NaN              NaN  \n",
       "               accuracy mean      59.830       60.544000        60.891000  \n",
       "                        std        3.526             NaN              NaN  \n",
       "Log Regression f1_score mean      53.030       50.769000        47.619000  \n",
       "                        std        3.446             NaN              NaN  \n",
       "               accuracy mean      58.009       56.463000        56.436000  \n",
       "                        std        2.402             NaN              NaN  \n",
       "traj_len       traj_len total   1536.000      147.000000       202.000000  \n",
       "               percent  Car        0.500        0.482993         0.465347  \n",
       "                        Taxi       0.500        0.517007         0.534653  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "traj_lens = np.arange(300,450, step=50)\n",
    "models = {\n",
    "        'Random Forest': Pipeline([('scaler', StandardScaler()), ('rf', RandomForestClassifier())]),\n",
    "        'AdaBoost':Pipeline([('scaler', StandardScaler()), ('abc', AdaBoostClassifier())]) ,\n",
    "        'SVM': Pipeline([('scaler', StandardScaler()), ('svc', SVC(max_iter=10000))]) ,\n",
    "        'Log Regression': Pipeline([('scaler', StandardScaler()), ('lr', LogisticRegression(max_iter=10000))]) \n",
    "    }\n",
    "\n",
    "df_acc = pd.DataFrame(index=pd.MultiIndex.from_product([models.keys(),['f1_score','accuracy'], ['mean','std']]))\n",
    "overlap = 0.6\n",
    "min_movement_limit = 0.75\n",
    "speed_limit = 0\n",
    "k = 5\n",
    "validation_ratio = 0.2\n",
    "kf = StratifiedKFold(n_splits=k, shuffle=True)\n",
    "accs = np.zeros(k)\n",
    "f1 = np.zeros(k)\n",
    "\n",
    "\n",
    "for traj_len in traj_lens:\n",
    "\n",
    "    #get length of trajectory in each id\n",
    "    df_traj_list = df.groupby(['file_name','id','edge_id',]).count()['lat']\n",
    "    \n",
    "    #limit trajectory length to greater than traj_len\n",
    "    df_traj_list = df_traj_list[df_traj_list>= traj_len]\n",
    "    df2 = df[df.index.droplevel('time').isin(df_traj_list.index.to_list())].copy()\n",
    "    df_train,df_val = validation_set(df2,validation_ratio)\n",
    "    \n",
    "    #process trajectories further\n",
    "    df_train = process_traj(df_train,traj_len,overlap,speed_limit,min_movement_limit)\n",
    "    df_val = process_traj(df_val,traj_len,overlap,speed_limit,min_movement_limit)\n",
    "\n",
    "    #aggregate trajectories\n",
    "    X,y = agg(df_train)\n",
    "    #include index for validation dataframes (needed for voting method)\n",
    "    X_val,y_val = agg(df_val,True)\n",
    "\n",
    "    #store percent cars and taxis\n",
    "    print(\"No of trajectories: \",len(X))\n",
    "    df_acc.loc[('traj_len','traj_len','total'), (str(traj_len)+'_kfold')] = len(X)\n",
    "    df_acc.loc[('traj_len','percent','Car'), (str(traj_len)+'_kfold')] = sum(y == 'Car')/len(X)\n",
    "    df_acc.loc[('traj_len','percent','Taxi'), (str(traj_len)+'_kfold')] = sum(y == 'Taxi')/ len(X)\n",
    "    \n",
    "    woedge_count = y_val.reset_index(['traj','edge_id'],drop = True).reset_index().drop_duplicates()\n",
    "    df_acc.loc[('traj_len','traj_len','total'), (str(traj_len)+'_val_woedge')] = len(woedge_count)\n",
    "    df_acc.loc[('traj_len','percent','Car'), (str(traj_len)+'_val_woedge')] = sum(woedge_count.type == 'Car')/len(woedge_count)\n",
    "    df_acc.loc[('traj_len','percent','Taxi'), (str(traj_len)+'_val_woedge')] =sum(woedge_count.type == 'Taxi')/len(woedge_count)\n",
    "    \n",
    "    by_edge_count = y_val.reset_index('traj',drop = True).reset_index().drop_duplicates()\n",
    "    df_acc.loc[('traj_len','traj_len','total'), (str(traj_len)+'_val_by_edge')] = len(by_edge_count)\n",
    "    df_acc.loc[('traj_len','percent','Car'), (str(traj_len)+'_val_by_edge')] = sum(by_edge_count.type == 'Car')/len(by_edge_count)\n",
    "    df_acc.loc[('traj_len','percent','Taxi'), (str(traj_len)+'_val_by_edge')] = sum(by_edge_count.type == 'Taxi')/len(by_edge_count)\n",
    "    \n",
    "    # fit different models\n",
    "    for name, model in models.items():\n",
    "        for i, (train_index, test_index) in enumerate(kf.split(X,y)):\n",
    "            \n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            accs[i],f1[i] = train_and_accuracy(X_train, y_train,X_test,y_test, model)\n",
    "        \n",
    "        df_acc.loc[(name, 'accuracy','mean'), (str(traj_len)+'_kfold')] = round(100*accs.mean(), 3)\n",
    "        df_acc.loc[(name, 'accuracy','std'), (str(traj_len)+'_kfold')] = round(100*accs.std(), 3)\n",
    "        df_acc.loc[(name, 'f1_score','mean'),(str(traj_len)+'_kfold')] = round(100*f1.mean(), 3)\n",
    "        df_acc.loc[(name, 'f1_score','std'), (str(traj_len)+'_kfold')] = round(100*f1.std(), 3)\n",
    "\n",
    "        val_accs,val_f1 = val_voting_accuracy(X, y,X_val,y_val, model)\n",
    "        df_acc.loc[(name, 'accuracy','mean'), (str(traj_len)+'_val_woedge')] = round(100*val_accs, 3)\n",
    "        df_acc.loc[(name, 'f1_score','mean'),(str(traj_len)+'_val_woedge')] = round(100*val_f1, 3)\n",
    "        \n",
    "        val_accs,val_f1 = val_voting_accuracy(X, y,X_val,y_val, model,by_edge = True)\n",
    "        df_acc.loc[(name, 'accuracy','mean'), (str(traj_len)+'_val_by_edge')] = round(100*val_accs, 3)\n",
    "        df_acc.loc[(name, 'f1_score','mean'),(str(traj_len)+'_val_by_edge')] = round(100*val_f1, 3)\n",
    "\n",
    "        print(name, 'complete.')\n",
    "\n",
    "    print('trajectory length', traj_len, 'complete.')\n",
    "\n",
    "df_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Cars in validation set 127, No of Taxis in validation set 127\n"
     ]
    }
   ],
   "source": [
    "\n",
    "traj_lens = np.arange(200,450, step=50)\n",
    "df_acc = pd.DataFrame(index=pd.MultiIndex.from_product([models.keys(),['f1_score','accuracy'], ['mean','std']]))\n",
    "overlap = 0.6\n",
    "min_movement_limit = 0.75\n",
    "speed_limit = 0\n",
    "k = 5\n",
    "validation_ratio = 0.2\n",
    "kf = StratifiedKFold(n_splits=k, shuffle=True)\n",
    "accs = np.zeros(k)\n",
    "f1 = np.zeros(k)\n",
    "\n",
    "for j in range(0,5):\n",
    "    \n",
    "    for traj_len in traj_lens:\n",
    "\n",
    "        #get length of trajectory in each id\n",
    "        df_traj_list = df.groupby(['file_name','id','edge_id',]).count()['lat']\n",
    "\n",
    "        #limit trajectory length to greater than traj_len\n",
    "        df_traj_list = df_traj_list[df_traj_list>= traj_len]\n",
    "        df2 = df[df.index.droplevel('time').isin(df_traj_list.index.to_list())].copy()\n",
    "        df_train,df_val = validation_set(df2,validation_ratio)\n",
    "\n",
    "        #process trajectories further\n",
    "        df_train = process_traj(df_train,traj_len,overlap,speed_limit,min_movement_limit,j)\n",
    "        df_val = process_traj(df_val,traj_len,overlap,speed_limit,min_movement_limit,j)\n",
    "\n",
    "        #aggregate trajectories\n",
    "        X,y = agg(df_train)\n",
    "        #include index for validation dataframes (needed for voting method)\n",
    "        X_val,y_val = agg(df_val,True)\n",
    "\n",
    "        #store percent cars and taxis\n",
    "        print(\"No of trajectories: \",len(X))\n",
    "        df_acc.loc[('traj_len','traj_len','total'), (str(traj_len)+'_kfold')] = len(X)\n",
    "        df_acc.loc[('traj_len','percent','Car'), (str(traj_len)+'_kfold')] = sum(y == 'Car')/len(X)\n",
    "        df_acc.loc[('traj_len','percent','Taxi'), (str(traj_len)+'_kfold')] = sum(y == 'Taxi')/ len(X)\n",
    "\n",
    "        woedge_count = y_val.reset_index(['traj','edge_id'],drop = True).reset_index().drop_duplicates()\n",
    "        df_acc.loc[('traj_len','traj_len','total'), (str(traj_len)+'_val_woedge')] = len(woedge_count)\n",
    "        df_acc.loc[('traj_len','percent','Car'), (str(traj_len)+'_val_woedge')] = sum(woedge_count.type == 'Car')/len(woedge_count)\n",
    "        df_acc.loc[('traj_len','percent','Taxi'), (str(traj_len)+'_val_woedge')] =sum(woedge_count.type == 'Taxi')/len(woedge_count)\n",
    "\n",
    "        by_edge_count = y_val.reset_index('traj',drop = True).reset_index().drop_duplicates()\n",
    "        df_acc.loc[('traj_len','traj_len','total'), (str(traj_len)+'_val_by_edge')] = len(by_edge_count)\n",
    "        df_acc.loc[('traj_len','percent','Car'), (str(traj_len)+'_val_by_edge')] = sum(by_edge_count.type == 'Car')/len(by_edge_count)\n",
    "        df_acc.loc[('traj_len','percent','Taxi'), (str(traj_len)+'_val_by_edge')] = sum(by_edge_count.type == 'Taxi')/len(by_edge_count)\n",
    "\n",
    "        # fit different models\n",
    "        for name, model in models.items():\n",
    "            for i, (train_index, test_index) in enumerate(kf.split(X,y)):\n",
    "\n",
    "                X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "                y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "                accs[i],f1[i] = train_and_accuracy(X_train, y_train,X_test,y_test, model)\n",
    "\n",
    "            df_acc.loc[(name, 'accuracy','mean'), (str(traj_len)+'_kfold')] = round(100*accs.mean(), 3)\n",
    "            df_acc.loc[(name, 'accuracy','std'), (str(traj_len)+'_kfold')] = round(100*accs.std(), 3)\n",
    "            df_acc.loc[(name, 'f1_score','mean'),(str(traj_len)+'_kfold')] = round(100*f1.mean(), 3)\n",
    "            df_acc.loc[(name, 'f1_score','std'), (str(traj_len)+'_kfold')] = round(100*f1.std(), 3)\n",
    "\n",
    "            val_accs,val_f1 = val_voting_accuracy(X, y,X_val,y_val, model)\n",
    "            df_acc.loc[(name, 'accuracy','mean'), (str(traj_len)+'_val_woedge')] = round(100*val_accs, 3)\n",
    "            df_acc.loc[(name, 'f1_score','mean'),(str(traj_len)+'_val_woedge')] = round(100*val_f1, 3)\n",
    "\n",
    "            val_accs,val_f1 = val_voting_accuracy(X, y,X_val,y_val, model,by_edge = True)\n",
    "            df_acc.loc[(name, 'accuracy','mean'), (str(traj_len)+'_val_by_edge')] = round(100*val_accs, 3)\n",
    "            df_acc.loc[(name, 'f1_score','mean'),(str(traj_len)+'_val_by_edge')] = round(100*val_f1, 3)\n",
    "\n",
    "            print(name, 'complete.')\n",
    "            \n",
    "        print('trajectory length', traj_len, 'complete.')\n",
    "\n",
    "    print(\"vehicle density >= \",j)\n",
    "    print(df_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
