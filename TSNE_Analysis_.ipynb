{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Break Down of the TSNE Plots \n",
    "I am here to provide some insights about the clustering structure of the the base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import networkx as nx\n",
    "from networkx import algorithms \n",
    "import math\n",
    "from numpy import arctan2, sin, cos, sqrt, radians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'osmnx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-8553333be723>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mosmnx\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mox\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'osmnx'"
     ]
    }
   ],
   "source": [
    "import osmnx as ox "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-bc908e525787>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mData\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mData\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Data'"
     ]
    }
   ],
   "source": [
    "from Data import Data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the graph for our data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ox' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-5339911d34fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_from_address\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Athens, Municipality of Athens, Regional Unit of Central Athens, Attica, 10667, Greece'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ox' is not defined"
     ]
    }
   ],
   "source": [
    "graph = ox.graph_from_address('Athens, Municipality of Athens, Regional Unit of Central Athens, Attica, 10667, Greece', network_type='drive')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data.py Functions:\n",
    "I am modifying on the data.py functions to concate the dataframes from different blocks ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    " def process_csv(name):\n",
    "        \"pre processing function to turn csv file into usable material for `process`\"\n",
    "        in_fname = name\n",
    "\n",
    "        with open(in_fname, \"r\") as f:\n",
    "            temp = f.readlines()\n",
    "    \n",
    "        rows = temp[1:]\n",
    "        return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(row_str, H, D, col_names, idx_names):\n",
    "        \"Creates multi index table using 'track_id' and 'time' as the indexes. Only creates table for each index.\"\n",
    "        parts = row_str.strip().strip(\";\").split(\";\")\n",
    "        header = parts[:H]\n",
    "        data = np.array(parts[H:], dtype=np.float)\n",
    "        data = data.reshape(-1, D)\n",
    "\n",
    "        # create MultiIndex from id and time\n",
    "        timesteps = data[:,-1]\n",
    "        id_arr = np.full(timesteps.shape, int(header[0].strip()))\n",
    "        tups = list(zip(id_arr, timesteps))\n",
    "        mul = pd.MultiIndex.from_tuples(tups, names=idx_names)\n",
    "\n",
    "        data = data[:,:-1] # exclude time from data\n",
    "        df = pd.DataFrame(data, columns=col_names, index=mul)\n",
    "        df = df.assign(\n",
    "            type=header[1].strip(),\n",
    "            traveled_d=float(header[2]),\n",
    "            avg_speed=float(header[3])\n",
    "        )\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create(csv_file):\n",
    "        H = 4 #header length \n",
    "        D = 6 #data length\n",
    "        idx_names = ['id', 'time']\n",
    "        col_names = ['lat', 'lon', 'speed', 'lon_acc', 'lat_acc']\n",
    "        a = process_csv(csv_file)\n",
    "        frames = [process(a[i], H, D, col_names, idx_names) for i in range(len(a))]\n",
    "        df = pd.concat(frames)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering and Aggregating functions:\n",
    "I am modifying some of the feature engineering functions and creating a couple of aggregating functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median(df):\n",
    "    medians = []\n",
    "    medians.append(df.iloc[0]['type'])\n",
    "    for i in ['speed', 'lon_acc', 'lat_acc', 'traveled_d', 'avg_speed', 'bearing']:\n",
    "        medians.append(np.median(df[i].dropna()))\n",
    "    return medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AVG(df):\n",
    "    avgs = []\n",
    "    avgs.append(df.iloc[0]['type'])\n",
    "    for i in ['speed', 'lon_acc', 'lat_acc', 'traveled_d', 'avg_speed', 'bearing']:\n",
    "        avgs.append(np.average(df[i].dropna()))\n",
    "    return avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stdev(df):\n",
    "    stdevss = []\n",
    "    stdevss.append(df.iloc[0]['type'])\n",
    "    for i in ['speed', 'lon_acc', 'lat_acc', 'traveled_d', 'avg_speed', 'bearing']:\n",
    "        stdevss.append(np.median(df[i].dropna()))\n",
    "    return medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bearing(df):\n",
    "    \"\"\"calculates and adds bearing column to dataframe\n",
    "    Example usage:\n",
    "        df = csv_to_df('sample.csv')\n",
    "        df = bearing(df)\n",
    "    \"\"\"\n",
    "    df['bearing'] = \\\n",
    "        df.groupby('id', as_index=False, group_keys=False) \\\n",
    "        .apply(__calc_bearings)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __bearing(c1, c2):\n",
    "    \"\"\"credit to https://bit.ly/3amjz0Q for bearing formula\"\"\"\n",
    "    lat1,lon1 = c1\n",
    "    lat2,lon2 = c2\n",
    "    \n",
    "    dL = lon2 - lon1\n",
    "    x = cos(lon2) * sin(dL)\n",
    "    y = cos(lat1) * sin(lat2) - sin(lat1) * cos(lat2) * cos(dL)\n",
    "    return arctan2(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __calc_bearings(df):\n",
    "    \"\"\"returns a multi-indexed dataframe of bearings at each timestep for vehicle with specified ID\"\"\"\n",
    "    df1 = df\n",
    "    df2 = df.shift(-1)\n",
    "\n",
    "    c1 = (df1['lat'], df1['lon'])\n",
    "    c2 = (df2['lat'], df2['lon'])\n",
    "    df3 = __bearing(c1, c2)\n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __calc_directions(df):\n",
    "    df1 = df\n",
    "    df2 = df.shift(-1)\n",
    "    df3 = (df1['edge_progress'] < df2['edge_progress']).astype(int)\n",
    "    if len(df3) > 1:\n",
    "        df3.iloc[-1] = df3.iloc[-2]\n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    " def nearest_graph_data(df, graph):\n",
    "    \"\"\"uses osmnx to find nearest node and edge data, calculates \n",
    "    progress along nearest edge as a ratio, and adds these features\n",
    "    as columns to the dataframe\n",
    "    Example usage:\n",
    "        df = csv_to_df('sample.csv')\n",
    "        graph = ox.graph_from_address('address_here', network_type='drive') \n",
    "        df = nearest_graph_data(df, graph)\n",
    "    \"\"\"\n",
    "    df['nearest_node'],             \\\n",
    "    df['nearest_edge_start_node'],  \\\n",
    "    df['nearest_edge_end_node'],    \\\n",
    "    df['edge_progress']             \\\n",
    "        = zip(*df.apply(__construct_graph_data_cols(graph), axis=1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def direction(df):\n",
    "    \"\"\"adds column that determiens which direction the vehicle is moving along an edge.\n",
    "    1 if moving from node with smaller id to node with larger id, 0 otherwise.\n",
    "    Note: `nearest_graph_data` must have been run on this df, otherwise this will fail!\n",
    "    Example usage:\n",
    "        df = csv_to_df('sample.csv')\n",
    "        df = direction(df)\n",
    "    \"\"\"\n",
    "    df['dir'] = \\\n",
    "        df.groupby(\n",
    "            ['id', 'nearest_edge_start_node', 'nearest_edge_end_node'], \n",
    "            as_index=False, group_keys=False) \\\n",
    "        .apply(__calc_directions)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    " def _calc_vehicle_density(df):\n",
    "    \"\"\"returns a dataframe of the unique edges (nearest_edge_start_node and neares_edge_end_node pairs) per direction (0 or 1) for edge progress intervals (in the          range(0.0:0.9), 0.0 represents edge progress between 0-10%, 0.1 represents edge progress between 10-20% and so on. \n",
    "        df must have been processed by `direction` first. Example usage: \n",
    "        df = csv_to_df(csv.file)\n",
    "        graph = ox.graph_from_address('Athens, Municipality of Athens, Regional Unit of Central Athens, Attica, 10667, Greece', network_type='drive')  \n",
    "        df = nearest_graph_data(df,graph)\n",
    "        df = direction(df)\n",
    "        vehicle_densities = _calc_vehicle_density(df)\n",
    "     \"\"\"\n",
    "    df['edge_progress_intervals'] = df.groupby(['nearest_edge_start_node'])['edge_progress'].transform(lambda x: x-x%0.1)\n",
    "    df2 = df.reset_index().groupby(['nearest_edge_start_node','nearest_edge_end_node','dir','edge_progress_intervals']).agg({'id':['nunique']})\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
